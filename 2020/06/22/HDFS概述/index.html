<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HDFS概述 | zxj</title><meta name="keywords" content="Hadoop"><meta name="author" content="Xiangjie"><meta name="copyright" content="Xiangjie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="HDFS概述HDFS产生背景随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作下同管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式管理系统的一种。 HDFS定义HDFS(Hadoop Distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS概述">
<meta property="og:url" content="https://awslzhang.top/2020/06/22/HDFS%E6%A6%82%E8%BF%B0/index.html">
<meta property="og:site_name" content="zxj">
<meta property="og:description" content="HDFS概述HDFS产生背景随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作下同管理的磁盘中，但是不方便管理和维护，迫切需要一种系统来管理多台机器上的文件，这就是分布式文件管理系统。HDFS只是分布式管理系统的一种。 HDFS定义HDFS(Hadoop Distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/06/22/xIQlAhrgUHqSa27.png">
<meta property="article:published_time" content="2020-06-22T11:41:47.000Z">
<meta property="article:modified_time" content="2021-01-01T05:49:59.940Z">
<meta property="article:author" content="Xiangjie">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/06/22/xIQlAhrgUHqSa27.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://awslzhang.top/2020/06/22/HDFS%E6%A6%82%E8%BF%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Xiangjie","link":"链接: ","source":"来源: zxj","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2021-01-01 13:49:59'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="/atom.xml" title="zxj" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">85</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/06/22/xIQlAhrgUHqSa27.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">zxj</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HDFS概述</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-06-22T11:41:47.000Z" title="发表于 2020-06-22 19:41:47">2020-06-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-01T05:49:59.940Z" title="更新于 2021-01-01 13:49:59">2021-01-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h1><h2 id="HDFS产生背景"><a href="#HDFS产生背景" class="headerlink" title="HDFS产生背景"></a>HDFS产生背景</h2><p>随着数据量越来越大，在一个操作系统存不下所有的数据，那么就分配到更多的操作下同管理的磁盘中，但是不方便管理和维护，迫切<font color="red">需要一种系统来管理多台机器上的文件</font>，这就是分布式文件管理系统。HDFS只是分布式管理系统的一种。</p>
<h2 id="HDFS定义"><a href="#HDFS定义" class="headerlink" title="HDFS定义"></a>HDFS定义</h2><p>HDFS(Hadoop Distributed File System)，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p>
<p>HDFS的适用场景：</p>
<ol>
<li>一次写入</li>
<li>多次读出</li>
<li>文件不修改</li>
</ol>
<h2 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h2><p><strong>优点</strong></p>
<ol>
<li>通过<a href="#HDFS%E5%A4%87%E4%BB%BD%E6%9C%BA%E5%88%B6%F0%9F%94%BA">备份机制</a>提供高容错性</li>
<li>适合处理大数据</li>
<li>可构建在廉价机器上</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>不适合低延时数据访问</li>
<li>无法高校的对大量小文件按进行存储</li>
<li>不支持并发写入、文件随机修改</li>
</ol>
<h2 id="HDFS组成架构🔺"><a href="#HDFS组成架构🔺" class="headerlink" title="HDFS组成架构🔺"></a>HDFS组成架构🔺</h2><h3 id="HDFS分布式存储的角色"><a href="#HDFS分布式存储的角色" class="headerlink" title="HDFS分布式存储的角色"></a>HDFS分布式存储的角色</h3><p>NameNode、SecondaryNode、DataNode</p>
<p><img src="https://i.loli.net/2020/06/22/9q1IKBtUJlD87T5.png" alt="image-20200622201510707"></p>
<h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><p><strong>作用</strong></p>
<ol>
<li>掌控全局，管理DataNode和元数据(对数据进行描述的数据)</li>
<li>接收客户端client的读或者是写请求</li>
<li>收集DataNode汇报的Block列表信息</li>
<li>保存上传文件的所有者，权限，上传时间，Block表：Blockid，Block副本位置（备份）</li>
</ol>
<p><strong>构成</strong></p>
<ol>
<li>edits(存放着能对元数据进行更改的操作)</li>
<li>fsimage(元数据信息) ：{edits文件会被SNN拿到并重演合并形成新的fsimage文件，把新文件持久化到本地，并推送给NN}</li>
<li>Block的位置信息，DataNode的心跳信息(启动后每3s发送)，文件的拥有者、权限、上传时间：(前三个是client第一次汇报时存取)、block的位置(在每个block传输完毕，由DN汇报得来)</li>
</ol>
<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3><p>DataNode是一个存储数据的节点，它的存储单位是block块。</p>
<p><strong>作用</strong></p>
<ol>
<li><font color="red">存储Block块(HDFS中不是以文件为基础存储的，是把文件切分为数据块来进行存储的)，默认128M</font></li>
<li>执行数据块的读写请求</li>
</ol>
<p><strong>为什么块的大小不能设置太小，也不能设置太大？</strong></p>
<ol>
<li>太小会导致增加寻址时间。</li>
<li>太大会导致MapReduce分析计算变慢。</li>
</ol>
<h3 id="SecondaryNameNode"><a href="#SecondaryNameNode" class="headerlink" title="SecondaryNameNode"></a>SecondaryNameNode</h3><p>并非NameNode的热备，当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</p>
<p><strong>作用</strong></p>
<ol>
<li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode</li>
<li>紧急情况下，辅助恢复NameNode</li>
</ol>
<h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><p>客户端</p>
<ol>
<li>文件切分。文件上传HDFS时，Client将文件切分成一个个的Block，然后上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读/写入数据</li>
<li>Client提供一些命令来管理HDFS，比如Name Node格式化</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作</li>
</ol>
<h1 id="HDFS的Shell操作"><a href="#HDFS的Shell操作" class="headerlink" title="HDFS的Shell操作"></a>HDFS的Shell操作</h1><p><code>hdfs dfs</code>或者<code>hadoop fs</code></p>
<p>请<code>hadoop fs -hlep</code>查看</p>
<h1 id="HDFS备份机制🔺"><a href="#HDFS备份机制🔺" class="headerlink" title="HDFS备份机制🔺"></a>HDFS备份机制🔺</h1><p>一份数据默认有2份备份，所以一个数据块要存3份。即一份数据要存储在3个DataNode节点中，1个DataNode存储一份数据块，相同的数据块不会在同一DataNode中备份。那么这3个DataNode节点是如何选择的呢？这涉及到集群内提交和集群外提交，直接上结论：([结论依据：就近法则](# 网络拓扑-节点距离计算))</p>
<p><strong>集群内提交</strong></p>
<ol>
<li>第1个DataNode通常是本机(如果本机是DataNode的话)</li>
<li>其余的1个是和第1个DataNode同机架上的其他一台DataNode</li>
<li>最后的1个是和1，2号服务器不同机架的随机一台DataNode</li>
</ol>
<p><strong>客户端提交(集群外提交)</strong></p>
<ol>
<li>第1个存放在一个负载不是很高的一台服务器上</li>
<li>第2个存储在与第1个不同机架的随机一台服务器上</li>
<li> 第3个存在放与第1个相同的机架上，但是不是同一台服务器上的随机一台服务器。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.</span><br></pre></td></tr></table></figure>

<h1 id="HDFS的数据流🔺"><a href="#HDFS的数据流🔺" class="headerlink" title="HDFS的数据流🔺"></a>HDFS的数据流🔺</h1><h2 id="HDFS的写数据流程"><a href="#HDFS的写数据流程" class="headerlink" title="HDFS的写数据流程"></a>HDFS的写数据流程</h2><h3 id="剖析文件写入"><a href="#剖析文件写入" class="headerlink" title="剖析文件写入"></a>剖析文件写入</h3><p><img src="https://i.loli.net/2020/06/22/WZkbuTswchHERdJ.gif" alt="pic"></p>
<ol>
<li>Client通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否存在，父目录是否存在。然后NameNode返回是否可以上传</li>
<li>客户端将本地大文件进行<strong>逻辑</strong>分块，并向NameNode请求上传第一块数据</li>
<li>NameNode返回3(HDFS默认存储3份)个DataNode节点，假设为dn1、dn2、dn3([有讲究](# NameNode返回多个DataNode节点之间的关系))</li>
<li>客户端通过开启输出流FSDataOutPutStream，请求dn1上传数据，同时dn1收到请求后继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成</li>
<li>dn1、dn2、dn3逐级应答客户端</li>
<li>客户端开始往dn1上传第一个数据块Black(先从磁盘读取数据到一个本地内存缓存)，以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</li>
<li>当一个Block传输完成后，客户端再次请求NameNode返回上传第二个Block的3个DataNode节点。(重复执行3-7步)</li>
<li>客户端发送数据传输完成标志，并关闭输入流。</li>
</ol>
<p><img src="https://i.loli.net/2020/06/22/sGcpDPR5eLnt329.png" alt="image-20200622213821279"></p>
<h4 id="NameNode返回多个DataNode节点之间的关系"><a href="#NameNode返回多个DataNode节点之间的关系" class="headerlink" title="NameNode返回多个DataNode节点之间的关系"></a>NameNode返回多个DataNode节点之间的关系</h4><p>以上面流程第三步为例，首先dn1是距离client端最近的一个几点，dn2、dn3是根据dn1计算得出的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack.</span><br></pre></td></tr></table></figure>

<p>通过官方描述可知：3个DataNode应该是同一机架2个，最后1个存放在不同机架。以防机架故障数据丢失。</p>
<p>[在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？](# 网络拓扑-节点距离计算)</p>
<h3 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h3><p>节点距离：两个节点到达最近的共同祖先的距离总和。</p>
<p><img src="https://i.loli.net/2020/06/23/dG8ynIozuTgxlqZ.png" alt="image-20200623104447002"></p>
<p><strong>集群内提交</strong></p>
<p>假设数据中心d1机架r1中的节点n1上提交，则n1是第一个被选择的节点，第二个节点是相同机架上的其他节点(n0/n2)，最后一个节点是除了r1机架外的一台节点。</p>
<p><strong>集群外提交</strong></p>
<p>随便选择一台负载不高的节点作为第一个，二三个跟上面选择一致。</p>
<h2 id="HDFS的下载数据流程"><a href="#HDFS的下载数据流程" class="headerlink" title="HDFS的下载数据流程"></a>HDFS的下载数据流程</h2><p>如果所示：</p>
<p><img src="https://i.loli.net/2020/06/23/ERuKIG9QjhDJbpi.gif" alt="gif5"></p>
<ol>
<li>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li>
<li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</li>
<li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</li>
<li>最后NameNode返回数据传输完成，然后客户端关闭输入流。</li>
</ol>
<h1 id="NameNode和SecondaryNameNode🔺"><a href="#NameNode和SecondaryNameNode🔺" class="headerlink" title="NameNode和SecondaryNameNode🔺"></a>NameNode和SecondaryNameNode🔺</h1><h2 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h2><p><strong>思考：NameNode中的元数据是存储在哪里的？</strong></p>
<p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。<font color="red">因此，元数据需要存放在内存中。</font>但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。<font color="red">因此它还在在磁盘中备份一份元数据称为FsImage。</font></p>
<p>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。<font color="red">因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。(Edits也在磁盘中，由NameNode持久化)</font>这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。</p>
<p>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。<font color="red">因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并，并持久化到磁盘。</font></p>
<p>NameNode不能持久化fsimage到磁盘，这样对内存全部持久化，会锁内存。此时不能提供服务。</p>
<p>SecondaryNamenode就是这样减轻NameNode的负担的。</p>
<p><img src="https://i.loli.net/2020/06/23/sRymkSict2Zh1WU.png" alt="NN和2NN工作机制"></p>
<ul>
<li>第一阶段：NameNode启动<ol>
<li>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。NameNode对其进行合并(仅此一次)</li>
<li>客户端对元数据进行增删改的请求(读请求不会造成元数据更改，不会触发Edits文件修改)</li>
<li>NameNode记录操作日志，更新滚动日志</li>
<li>NameNode在内存中对元数据进行增删改</li>
</ol>
</li>
<li>第二阶段：Secondary NamaNode工作<ol>
<li>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果</li>
<li>Secondary NameNode请求执行CheckPoint</li>
<li>NameNode滚动正在写的Edits日志</li>
<li>将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode</li>
<li>Secondary NameNode加载编辑日志和镜像文件到内存，并合并</li>
<li>生成新的镜像文件fsimage.chkpoint</li>
<li>拷贝fsimage.chkpoint到NameNode</li>
<li>NameNode将fsimage.chkpoint重新命名成fsimage</li>
</ol>
</li>
</ul>
<h2 id="NN和2NN工作机制详解"><a href="#NN和2NN工作机制详解" class="headerlink" title="NN和2NN工作机制详解"></a>NN和2NN工作机制详解</h2><p><code>Fsimage</code>：NameNode内存中元数据序列化后形成的文件(磁盘中)。</p>
<p><code>Edits</code>：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。</p>
<p>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。</p>
<p>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。</p>
<p>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p>
<hr>
<p><code>Fsimage</code>、<code>Edits</code>类似于Redis的持久化的两种策略：<code>RDB</code>、<code>AOF</code></p>
<p><code>RDB</code>对Redis内存中的数据的镜像。</p>
<p><code>AOF</code>存放对数据操作的指令，来对原始数据进行指令操作做到恢复数据。</p>
<h2 id="怎么触发CheckPoint"><a href="#怎么触发CheckPoint" class="headerlink" title="怎么触发CheckPoint"></a>怎么触发CheckPoint</h2><p>上面的流程中是SecondaryNameNode主动询问NameNode是否需要checkPoint，那么也不可能SecondaryNameNode一直轮询询问NameNode。那么是怎么触发的呢？</p>
<ol>
<li>通常情况下，SecondaryNameNode每隔一小时执行一次。</li>
</ol>
<p>[hdfs-default.xml]</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>当操作次数达到1百万时，SecondaryNameNode执行一次。(一分钟检查一次)</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span> &gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="HDFS安全模式"><a href="#HDFS安全模式" class="headerlink" title="HDFS安全模式"></a>HDFS安全模式</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>NameNode启动时</strong></p>
<p>首先将镜像文件<code>Fsimage</code>载入内存，并执行编辑日志<code>Edits</code>中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的<code>Fsimage</code>和一个空的编辑日志。此时，NameNode开始监听DataNode的请求(DataNode向NameNode发送Block块信息)。<font color="red">这个过程期间，NameNode一直运行在安全模式，即NameNode的文件系统对于客户端来说是只读的。</font></p>
<p><strong>DataNode启动</strong></p>
<p><font color="red">系统中的数据块的位置并不是由NameNode维护的，而是以块列表的形式存储在DataNode中。</font>在系统的正常操作期间，NameNode会在内存中保留所有块位置的映射信息。在安全模式下，各个DataNode会向NameNode发送最新的块列表信息(离开安全模式后，周期性(1 hour)上报block信息)，NameNode了解到足够多的块位置信息后，即可高效运行文件系统。</p>
<p><strong>安全模式退出判断</strong></p>
<p>如果满足“最小副本条件”，NameNode会在30秒钟之后就退出安全模式。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别(1)。<font color="red">在启动一个刚刚格式化的HDFS集群时，因为系统没有任何块，所以NameNode不会进入安全模式。</font></p>
<h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p>
<ol>
<li><code>bin/hdfs dfsadmin -safemode get</code>    （功能描述：查看安全模式状态）</li>
<li><code>bin/hdfs dfsadmin -safemode enter</code>  （功能描述：进入安全模式状态）</li>
<li><code>bin/hdfs dfsadmin -safemode leave</code>   （功能描述：离开安全模式状态）</li>
<li><code>bin/hdfs dfsadmin -safemode wait</code>    （功能描述：等待安全模式状态）</li>
</ol>
<h1 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h1><p>DataNode工作机制，如图：</p>
<p><img src="https://i.loli.net/2020/06/23/QfneWoclTGrOAgi.png" alt="Snipaste_2020-06-23_18-32-58"></p>
<ol>
<li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</li>
<li>DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。</li>
<li>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入和退出一些机器。</li>
</ol>
<h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p><strong>思考：</strong>如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？</p>
<p>如下是DataNode节点保证数据完整性的方法。</p>
<ol>
<li>当DataNode读取Block的时候，它会计算CheckSum。</li>
<li>如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</li>
<li>Client读取其他DataNode上的Block。</li>
<li>DataNode在其文件创建后周期验证CheckSum，如图</li>
</ol>
<p><img src="https://i.loli.net/2020/06/23/JhT84BEmtibgopN.png" alt="image-20200623183440272"></p>
<h2 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h2><p><img src="https://i.loli.net/2020/06/23/AVx9db7gOmyvfL4.png" alt="image-20200623183557129"></p>
<p>需要注意的是<code>hdfs-site.xml</code> 配置文件中的<code>heartbeat.recheck.interval</code>的单位为<font color="red">毫秒</font>，<code>dfs.heartbeat.interval</code>的单位为<font color="red">秒</font>。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>300000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="安全增加DataNode"><a href="#安全增加DataNode" class="headerlink" title="安全增加DataNode"></a>安全增加DataNode</h2><p>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。</p>
<p><strong>环境准备</strong></p>
<ol>
<li>取一台集群内的节点，复制它，改IP改host名</li>
<li><strong>删除原来HDFS文件系统留存的文件</strong>(data、logs)</li>
<li>source一下配置文件</li>
</ol>
<p><strong>具体步骤</strong></p>
<p>直接启动DataNode，即可关联到集群</p>
<p><code>sbin/hadoop-daemon.sh start</code></p>
<p><strong>为什么这样设置就可以？</strong></p>
<p>这里为什么什么也不用改就能直接添加到集群中，因为最新节点开启DataNode后会自己主动去找到NameNode注册自己，那么从其他节点拷贝过来的hadoop配置里面有配置NameNode的信息，所以可以直接添加DataNode节点成功。</p>
<p>但是还是建议在集群中所有节点的Host文件添加最新的节点，这样展示好。</p>
<p><strong>之前Hadoop里面slaves文件配置的从节点的列表不用修改吗？</strong></p>
<p>hadoop配置文件中的<code>slave</code>文件只有在群起集群的时候才有用：<code>start-dfs.sh</code>，因为我们最后一个是集群运行时加入的，是他自己开启DataNode的，所以可以不用修改。这样我们关闭集群时，最新的不会关闭，开启集群时最新的会加入。</p>
<h2 id="安全退役DataNode"><a href="#安全退役DataNode" class="headerlink" title="安全退役DataNode"></a>安全退役DataNode</h2><p>有黑名单和白名单两种方式，其中白名单比较严格。</p>
<p>使用黑名单后，DataNode节点处于退役状态，不提供服务。但是节点列表还能查询到，此节点的DataNode进程还存在。</p>
<p>使用白名单后，DataNode节点直接删除。节点列表不展示，此节点的DataNode进程被杀死。</p>
<p><strong>所以，一般来说退役节点采用黑名单，白名单一般在多个集群时，为了集群间数据不被污染时设置。</strong></p>
<h3 id="添加白名单"><a href="#添加白名单" class="headerlink" title="添加白名单"></a>添加白名单</h3><p>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。</p>
<p>配置白名单的具体步骤如下：</p>
<ol>
<li>在NameNode的<code>/opt/module/hadoop-2.7.2/etc/hadoop</code>目录下创建<code>dfs.hosts</code>文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 集群内所有允许访问NameNode的主机名/IP</span></span><br><span class="line">hadoop201</span><br><span class="line">hadoop202</span><br><span class="line">hadoop203</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>在NameNode的<code>hdfs-site.xml</code>配置文件中增加<code>dfs.hosts</code>属性</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>配置文件分发</li>
<li>刷新NameNode，<code>hdfs dfsadmin -refreshNodes</code></li>
<li>更新ResourceManager节点，<code>yarn rmadmin -refreshNodes</code></li>
<li>如果数据不均衡，可以用命令实现集群的再平衡。<code>start-balancer.sh</code></li>
</ol>
<h3 id="黑名单退役"><a href="#黑名单退役" class="headerlink" title="黑名单退役"></a>黑名单退役</h3><p>在黑名单上面的主机都会被强制退出。</p>
<ol>
<li>在NameNode的<code>/opt/module/hadoop-2.7.2/etc/hadoop</code>目录下创建<code>dfs.hosts.exclude</code>文件</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加要退役的节点</span></span><br><span class="line">hadoop204</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>在NameNode的<code>hdfs-site.xml</code>配置文件中增加<code>dfs.hosts.exclude</code>属性</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>刷新NameNode、刷新ResourceManager。<code>hdfs dfsadmin -refreshNodes</code>、<code>yarn rmadmin -refreshNodes</code></li>
<li>如果数据不均衡，可以用命令实现集群的再平衡。<code>start-balancer.sh</code></li>
</ol>
<p>ps：其实白名单/黑名单方式，不需要把改的名单发送到其他节点的，只需要在NameNode那里刷新一下即可。</p>
<h1 id="HA"><a href="#HA" class="headerlink" title="HA"></a>HA</h1><table>
<thead>
<tr>
<th>hadoop201</th>
<th>hadoop202</th>
<th>hadoop203</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td></td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td></td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>ZK</td>
<td>ZK</td>
<td>ZK</td>
</tr>
<tr>
<td></td>
<td>ResourceManager</td>
<td></td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h2 id="核心配置"><a href="#核心配置" class="headerlink" title="核心配置"></a>核心配置</h2><p><strong>core-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">&lt;!-- 指定Hadoop运行时链接zookeeper --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:2181,hadoop202:2181,hadoop203:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="HDFS配置"><a href="#HDFS配置" class="headerlink" title="HDFS配置"></a>HDFS配置</h2><p><strong>hadoop-env.sh</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/modules/jdk1.8.0_152</span><br></pre></td></tr></table></figure>

<p><strong>hdfs-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">&lt;!-- 完全分布式集群名称 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- nn1的RPC通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- nn2的RPC通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop202:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- nn1的http通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- nn2的http通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop202:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop201:8485;hadoop202:8485;hadoop203:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--副本数 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 声明journalnode服务器存储目录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hadoop-2.7.2/data/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 关闭权限检查--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment">&lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span>                       <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS-HA自动故障转移 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="yarn配置"><a href="#yarn配置" class="headerlink" title="yarn配置"></a>yarn配置</h2><p><strong>yarn-env.sh</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/modules/jdk1.8.0_152</span><br></pre></td></tr></table></figure>

<p><strong>yarn-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--启用resourcemanager ha--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--声明两台resourcemanager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop202<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!--指定zookeeper集群的地址--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:2181,hadoop202:2181,hadoop203:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--启用自动恢复--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><font color="red">ps：注意：NameNode和ResourceManger如果不是同一台机器，不能在NameNode上启动 YARN，应该在ResouceManager所在的机器上启动YARN。</font></p>
<h2 id="MapReduce配置"><a href="#MapReduce配置" class="headerlink" title="MapReduce配置"></a>MapReduce配置</h2><p><strong>mapred-env.sh</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/modules/jdk1.8.0_152</span><br></pre></td></tr></table></figure>

<p><strong>mapred-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop201:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>mr-jobhistory-daemon.sh start historyserver</code>启动历史服务器</p>
<hr>
<ol>
<li>先开启Zookeeper</li>
<li>所有节点开启JournalNode：<code>hadoop-daemon.sh start journalnode</code></li>
<li>NameNode格式化(一次)，并启动:：<code>hdfs namenode -format</code>、<code>hadoop-daemon.sh start namenode</code></li>
<li>standbyNameNode执行<code>hdfs namenode -bootstarpStandby  </code></li>
<li>初始化ZKFC在Zookeeper中的状态，<code>hdfs zkfc -formatZK</code></li>
<li>关闭所有进程，<code>stop-dfs.sh</code></li>
<li>群起：<code>start-dfs.sh</code></li>
<li>群起：<code>start-yarn.sh</code></li>
<li>在另外一个ResourceManager节点上单独启动，<code>yarn-daemon.sh start resourcemanager</code></li>
</ol>
<hr>
<p><strong>记一个HA手动杀死<code>NameNode</code>，另外一个<code>NameNode</code>不自动切换状态的问问题</strong></p>
<ol>
<li>首先查看<code>hdfs-site.xml</code>的配置是否出错</li>
<li>查看两个<code>namenode</code>节点的namenode和zkfc的log日志。</li>
<li>(一开始Hadoop201是active，手动杀死Hadoop201的namenode)发现Hadoop202的zkfc</li>
<li>发现zkfc想通过sshfence的方式切换状态。却出现了错误</li>
</ol>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-07-01 23:24:45,815 WARN org.apache.hadoop.ha.SshFenceByTcpPort: PATH&#x3D;$PATH:&#x2F;sbin:&#x2F;usr&#x2F;sbin fuser -v -k -n tcp 9000 via ssh: bash: fuser: 未找到命令</span><br></pre></td></tr></table></figure>

<p>以上所述，原因是最小化安装centos的时候，没有fuser这个命令，导致无法fence，解决办法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install psmisc</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Xiangjie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://awslzhang.top/2020/06/22/HDFS%E6%A6%82%E8%BF%B0/">https://awslzhang.top/2020/06/22/HDFS%E6%A6%82%E8%BF%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://awslzhang.top" target="_blank">zxj</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/06/22/xIQlAhrgUHqSa27.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/06/26/MapReduce%E5%8E%9F%E7%90%86/"><img class="prev-cover" src="https://i.loli.net/2020/06/27/2xbLZqNQKHGoUu1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MapReduce原理</div></div></a></div><div class="next-post pull-right"><a href="/2020/06/22/Hadoop%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"><img class="next-cover" src="https://i.loli.net/2020/06/22/Wb7kUVafmZSOudC.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hadoop编译安装</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/07/15/Oozie调度/" title="Oozie调度"><img class="cover" src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/Oozie-logo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-15</div><div class="title">Oozie调度</div></div></a></div><div><a href="/2020/07/14/Sqoop的简单使用/" title="Sqoop的简单使用"><img class="cover" src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/sqoop-logo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-14</div><div class="title">Sqoop的简单使用</div></div></a></div><div><a href="/2020/07/04/Flume基本使用/" title="Flume基本使用"><img class="cover" src="https://i.loli.net/2020/07/04/FjyZ6DdUigWebJn.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-04</div><div class="title">Flume基本使用</div></div></a></div><div><a href="/2020/06/22/Hadoop编译安装/" title="Hadoop编译安装"><img class="cover" src="https://i.loli.net/2020/06/22/Wb7kUVafmZSOudC.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-22</div><div class="title">Hadoop编译安装</div></div></a></div><div><a href="/2020/06/26/MapReduce原理/" title="MapReduce原理"><img class="cover" src="https://i.loli.net/2020/06/27/2xbLZqNQKHGoUu1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-26</div><div class="title">MapReduce原理</div></div></a></div><div><a href="/2020/07/02/Hive概述/" title="Hive概述"><img class="cover" src="https://i.loli.net/2020/07/02/LEKTZ49OFH5Jo3C.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-02</div><div class="title">Hive概述</div></div></a></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Xiangjie</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">85</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XiangJie-Zhang" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:qluzxj@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">HDFS概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E4%BA%A7%E7%94%9F%E8%83%8C%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">HDFS产生背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%AE%9A%E4%B9%89"><span class="toc-number">1.2.</span> <span class="toc-text">HDFS定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.3.</span> <span class="toc-text">HDFS优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84%F0%9F%94%BA"><span class="toc-number">1.4.</span> <span class="toc-text">HDFS组成架构🔺</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%9A%84%E8%A7%92%E8%89%B2"><span class="toc-number">1.4.1.</span> <span class="toc-text">HDFS分布式存储的角色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NameNode"><span class="toc-number">1.4.2.</span> <span class="toc-text">NameNode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataNode"><span class="toc-number">1.4.3.</span> <span class="toc-text">DataNode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SecondaryNameNode"><span class="toc-number">1.4.4.</span> <span class="toc-text">SecondaryNameNode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Client"><span class="toc-number">1.4.5.</span> <span class="toc-text">Client</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E7%9A%84Shell%E6%93%8D%E4%BD%9C"><span class="toc-number">2.</span> <span class="toc-text">HDFS的Shell操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E5%A4%87%E4%BB%BD%E6%9C%BA%E5%88%B6%F0%9F%94%BA"><span class="toc-number">3.</span> <span class="toc-text">HDFS备份机制🔺</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81%F0%9F%94%BA"><span class="toc-number">4.</span> <span class="toc-text">HDFS的数据流🔺</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">HDFS的写数据流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%96%E6%9E%90%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span class="toc-number">4.1.1.</span> <span class="toc-text">剖析文件写入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NameNode%E8%BF%94%E5%9B%9E%E5%A4%9A%E4%B8%AADataNode%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">NameNode返回多个DataNode节点之间的关系</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">4.1.2.</span> <span class="toc-text">网络拓扑-节点距离计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS的下载数据流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#NameNode%E5%92%8CSecondaryNameNode%F0%9F%94%BA"><span class="toc-number">5.</span> <span class="toc-text">NameNode和SecondaryNameNode🔺</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">5.1.</span> <span class="toc-text">NN和2NN工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3"><span class="toc-number">5.2.</span> <span class="toc-text">NN和2NN工作机制详解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%A7%A6%E5%8F%91CheckPoint"><span class="toc-number">5.3.</span> <span class="toc-text">怎么触发CheckPoint</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">6.</span> <span class="toc-text">HDFS安全模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">6.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-number">6.2.</span> <span class="toc-text">基本语法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">7.</span> <span class="toc-text">DataNode工作机制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-number">7.1.</span> <span class="toc-text">数据完整性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%89%E7%BA%BF%E6%97%B6%E9%99%90%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">7.2.</span> <span class="toc-text">掉线时限参数设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E5%A2%9E%E5%8A%A0DataNode"><span class="toc-number">7.3.</span> <span class="toc-text">安全增加DataNode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E9%80%80%E5%BD%B9DataNode"><span class="toc-number">7.4.</span> <span class="toc-text">安全退役DataNode</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E7%99%BD%E5%90%8D%E5%8D%95"><span class="toc-number">7.4.1.</span> <span class="toc-text">添加白名单</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E5%90%8D%E5%8D%95%E9%80%80%E5%BD%B9"><span class="toc-number">7.4.2.</span> <span class="toc-text">黑名单退役</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HA"><span class="toc-number">8.</span> <span class="toc-text">HA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE"><span class="toc-number">8.1.</span> <span class="toc-text">核心配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E9%85%8D%E7%BD%AE"><span class="toc-number">8.2.</span> <span class="toc-text">HDFS配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#yarn%E9%85%8D%E7%BD%AE"><span class="toc-number">8.3.</span> <span class="toc-text">yarn配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E9%85%8D%E7%BD%AE"><span class="toc-number">8.4.</span> <span class="toc-text">MapReduce配置</span></a></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/01/10/Api%E5%92%8CSQL/" title="Api和SQL"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Api和SQL"/></a><div class="content"><a class="title" href="/2021/01/10/Api%E5%92%8CSQL/" title="Api和SQL">Api和SQL</a><time datetime="2021-01-10T03:51:40.000Z" title="发表于 2021-01-10 11:51:40">2021-01-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/02/Flink%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/" title="Flink状态编程和容错机制"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink状态编程和容错机制"/></a><div class="content"><a class="title" href="/2021/01/02/Flink%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/" title="Flink状态编程和容错机制">Flink状态编程和容错机制</a><time datetime="2021-01-02T10:06:02.000Z" title="发表于 2021-01-02 18:06:02">2021-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/23/Flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8CWaterMark/" title="Flink的时间语义和watermark"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink的时间语义和watermark"/></a><div class="content"><a class="title" href="/2020/12/23/Flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8CWaterMark/" title="Flink的时间语义和watermark">Flink的时间语义和watermark</a><time datetime="2020-12-23T10:59:07.000Z" title="发表于 2020-12-23 18:59:07">2020-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/17/Flink-API/" title="Flink Api学习"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink Api学习"/></a><div class="content"><a class="title" href="/2020/12/17/Flink-API/" title="Flink Api学习">Flink Api学习</a><time datetime="2020-12-17T12:36:28.000Z" title="发表于 2020-12-17 20:36:28">2020-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/17/ready/" title="ready!"><img src="https://images.pexels.com/photos/924824/pexels-photo-924824.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ready!"/></a><div class="content"><a class="title" href="/2020/12/17/ready/" title="ready!">ready!</a><time datetime="2020-12-16T16:02:06.000Z" title="发表于 2020-12-17 00:02:06">2020-12-17</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Xiangjie</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script></div></body></html>