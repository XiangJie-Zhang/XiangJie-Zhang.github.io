<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Flink Api学习 | zxj</title><meta name="keywords" content="Flink"><meta name="author" content="Xiangjie"><meta name="copyright" content="Xiangjie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="DataStream API所有的Flink程序都是由三部分组成的： Source 、Transformation 和 Sink。 Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出。 所以练习API，Source是必不可少的，没有数据源就没有第一步。这里使用手动造数据的方法，而Flink提供了一下方式。 搭建执行环境编写Flink程序的第一件">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink Api学习">
<meta property="og:url" content="https://awslzhang.top/2020/12/17/Flink-API/index.html">
<meta property="og:site_name" content="zxj">
<meta property="og:description" content="DataStream API所有的Flink程序都是由三部分组成的： Source 、Transformation 和 Sink。 Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出。 所以练习API，Source是必不可少的，没有数据源就没有第一步。这里使用手动造数据的方法，而Flink提供了一下方式。 搭建执行环境编写Flink程序的第一件">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://flink.apache.org/img/flink-header-logo.svg">
<meta property="article:published_time" content="2020-12-17T12:36:28.000Z">
<meta property="article:modified_time" content="2021-01-02T10:05:23.110Z">
<meta property="article:author" content="Xiangjie">
<meta property="article:tag" content="Flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://flink.apache.org/img/flink-header-logo.svg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://awslzhang.top/2020/12/17/Flink-API/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Xiangjie","link":"链接: ","source":"来源: zxj","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2021-01-02 18:05:23'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.0.2"><link rel="alternate" href="/atom.xml" title="zxj" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">84</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://flink.apache.org/img/flink-header-logo.svg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">zxj</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Flink Api学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-12-17T12:36:28.000Z" title="发表于 2020-12-17 20:36:28">2020-12-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-02T10:05:23.110Z" title="更新于 2021-01-02 18:05:23">2021-01-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>45分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="DataStream-API"><a href="#DataStream-API" class="headerlink" title="DataStream API"></a>DataStream API</h1><p>所有的Flink程序都是由三部分组成的： Source 、Transformation 和 Sink。</p>
<p>Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出。</p>
<p>所以练习API，Source是必不可少的，没有数据源就没有第一步。这里使用手动造数据的方法，而Flink提供了一下方式。</p>
<h2 id="搭建执行环境"><a href="#搭建执行环境" class="headerlink" title="搭建执行环境"></a>搭建执行环境</h2><p>编写Flink程序的第一件事情就是搭建执行环境。执行环境决定了程序是运行在单机上还是集群上。在DataStream API中，程序的执行环境是由StreamExecutionEnvironment设置的。在我们的例子中，我们通过调用静态getExecutionEnvironment()方法来获取执行环境。这个方法根据调用方法的上下文，返回一个本地的或者远程的环境。如果这个方法是一个客户端提交到远程集群的代码调用的，那么这个方法将会返回一个远程的执行环境。否则，将返回本地执行环境。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create a local stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> localEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createLocalEnvironment()</span><br><span class="line"><span class="comment">// create a remote stream execution environment</span></span><br><span class="line"><span class="keyword">val</span> remoteEnv = <span class="type">StreamExecutionEnvironment</span></span><br><span class="line">  .createRemoteEnvironment(</span><br><span class="line">    <span class="string">&quot;host&quot;</span>, <span class="comment">// hostname of JobManager</span></span><br><span class="line">    <span class="number">1234</span>, <span class="comment">// port of JobManager process</span></span><br><span class="line">    <span class="string">&quot;path/to/jarFile.jar&quot;</span></span><br><span class="line">  ) <span class="comment">// JAR file to ship to the JobManager</span></span><br></pre></td></tr></table></figure>

<p>接下来，我们使用<code>env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>来将我们程序的时间语义设置为事件时间。执行环境提供了很多配置选项，例如：设置程序的并行度和程序是否开启容错机制。</p>
<h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><ul>
<li>从集合中读取：fromElements、fromCollection</li>
<li>从文件中读取：readTextFile</li>
<li>从网络sock：socketTextStream</li>
<li>Kafka数据源 ：（额外导包）</li>
</ul>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p><strong>pom</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka-0.10_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>0.10是Kafka版本</p>
</blockquote>
<p>使用addSource通用数据源，addSource(SourceFunction)，使用富函数SourceFunction（需要隐式转换）也可以。下面的自定义数据源就是这个原理。</p>
<p>既然addSource需要SourceFunction的参数难道用我们自己实现吗，不用，既然我们导了包就能直接用现成的！</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> kafkaProps = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"> kafkaProps.setProperty(<span class="string">&quot;zookeeper.connect&quot;</span>, <span class="type">ZOOKEEPER_HOST</span>)</span><br><span class="line"> kafkaProps.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="type">KAFKA_BROKER</span>)</span><br><span class="line"> kafkaProps.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="type">TRANSACTION_GROUP</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//topicd的名字是new，schema默认使用SimpleStringSchema()即可</span></span><br><span class="line"> <span class="keyword">val</span> transaction = env</span><br><span class="line">   .addSource(</span><br><span class="line">     <span class="keyword">new</span> <span class="type">FlinkKafkaConsumer08</span>[<span class="type">String</span>](<span class="string">&quot;new&quot;</span>, <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>(), kafkaProps)</span><br><span class="line">   )</span><br></pre></td></tr></table></figure>

<h3 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h3><p>我们创建一个温度器，并随机它的数据：</p>
<p><strong>创建数据结构</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zxjgg.source</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">SensorReading</span>(<span class="params">id: <span class="type">String</span>, temperature: <span class="type">Double</span>, timestamp: <span class="type">Long</span></span>)</span></span><br></pre></td></tr></table></figure>

<p><strong>生成数据</strong></p>
<p>需要集成Flink的类，因为之后要用Flink来处理这些数据</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zxjgg.source</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.source.&#123;<span class="type">RichParallelSourceFunction</span>, <span class="type">SourceFunction</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SensorSource</span> <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>[<span class="type">SensorReading</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> running: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(sourceContext: <span class="type">SourceFunction</span>.<span class="type">SourceContext</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> random = <span class="keyword">new</span> <span class="type">Random</span>()</span><br><span class="line">    <span class="keyword">val</span> result = (<span class="number">1</span> to <span class="number">10</span>).map(x =&gt; (x + <span class="string">&quot;&quot;</span>, random.nextGaussian() * <span class="number">20</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line">      result.map(x =&gt; (x._1, x._2 + random.nextGaussian() * <span class="number">0.5</span>))</span><br><span class="line">      result.foreach(x =&gt; sourceContext.collect(<span class="type">SensorReading</span>(x._1, x._2, <span class="type">System</span>.currentTimeMillis())))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = running = <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>测试数据处理</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.zxjgg.source</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> value:<span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    value.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>你可能已经注意到Flink程序的定义和提交执行使用的就是正常的Scala或者Java的方法。大多数情况下，这些代码都写在一个静态main方法中。在我们的例子中，我们定义了Test对象，然后将大多数的应用程序逻辑放在了main()中。</p>
<p>Flink流处理程序的结构如下：</p>
<ol>
<li>创建Flink程序执行环境。</li>
<li>从数据源读取一条或者多条流数据</li>
<li>使用流转换算子实现业务逻辑</li>
<li>将计算结果输出到一个或者多个外部设备（可选）</li>
<li>执行程序</li>
</ol>
<p>接下来我们详细的学习一下这些部分。</p>
<h2 id="Sink"><a href="#Sink" class="headerlink" title="Sink"></a>Sink</h2><p>Flink没有类似于spark中foreach方法，让用户进行迭代的操作。虽有对外的输出操作都要利用Sink完成。最后通过类似如下方式完成整个任务最终输出操作。</p>
<p><code> stream.addSink(new MySink(xxxx))</code></p>
<p>官方提供了一部分的框架的sink。除此以外，需要用户自定义实现sink。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20210101142032322.png" alt="image-20210101142032322"></p>
<p>第三方：</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20210101142045980.png" alt="image-20210101142045980"></p>
<p>其他的需要自定义！！</p>
<h3 id="Kafka-1"><a href="#Kafka-1" class="headerlink" title="Kafka"></a>Kafka</h3><p>继上面的Kafka的Source，继续写Sink</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStream.addSink(<span class="keyword">new</span> <span class="type">FlinkKafkaProducer011</span>[<span class="type">String</span>](<span class="string">&quot;localhost:9092&quot;</span>, <span class="string">&quot;topic&quot;</span>, <span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()))</span><br></pre></td></tr></table></figure>

<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>因为官方没有Redis的Sink，但是Bahir提供了。所以需要引入它的包。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.bahir<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-redis_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>定义一个redis的mapper类，用于定义保存到redis时调用的命令：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRedisMapper</span> <span class="keyword">extends</span> <span class="title">RedisMapper</span>[<span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getCommandDescription</span></span>: <span class="type">RedisCommandDescription</span> = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">RedisCommandDescription</span>(<span class="type">RedisCommand</span>.<span class="type">HSET</span>, <span class="string">&quot;sensor_temperature&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getValueFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = t.temperature.toString</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKeyFromData</span></span>(t: <span class="type">SensorReading</span>): <span class="type">String</span> = t.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在主函数中调用：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">FlinkJedisPoolConfig</span>.<span class="type">Builder</span>().setHost(<span class="string">&quot;localhost&quot;</span>).setPort(<span class="number">6379</span>).build()</span><br><span class="line">dataStream.addSink( <span class="keyword">new</span> <span class="type">RedisSink</span>[<span class="type">SensorReading</span>](conf, <span class="keyword">new</span> <span class="type">MyRedisMapper</span>))</span><br></pre></td></tr></table></figure>

<h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>主函数中调用</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> httpHosts = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">HttpHost</span>]()</span><br><span class="line">httpHosts.add(<span class="keyword">new</span> <span class="type">HttpHost</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">9200</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> esSinkBuilder = <span class="keyword">new</span> <span class="type">ElasticsearchSink</span>.<span class="type">Builder</span>[<span class="type">SensorReading</span>]( httpHosts, <span class="keyword">new</span> <span class="type">ElasticsearchSinkFunction</span>[<span class="type">SensorReading</span>] &#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(t: <span class="type">SensorReading</span>, runtimeContext: <span class="type">RuntimeContext</span>, requestIndexer: <span class="type">RequestIndexer</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;saving data: &quot;</span> + t)</span><br><span class="line">    <span class="keyword">val</span> json = <span class="keyword">new</span> util.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line">    json.put(<span class="string">&quot;data&quot;</span>, t.toString)</span><br><span class="line">    <span class="keyword">val</span> indexRequest = <span class="type">Requests</span>.indexRequest().index(<span class="string">&quot;sensor&quot;</span>).`<span class="class"><span class="keyword">type</span>`(<span class="params">&quot;readingData&quot;</span>).<span class="title">source</span>(<span class="params">json</span>)</span></span><br><span class="line"><span class="class">    <span class="title">requestIndexer</span>.<span class="title">add</span>(<span class="params">indexRequest</span>)</span></span><br><span class="line"><span class="class">    <span class="title">println</span>(<span class="params">&quot;saved successfully&quot;</span>)</span></span><br><span class="line"><span class="class">  &#125;</span></span><br><span class="line"><span class="class">&#125; )</span></span><br><span class="line"><span class="class"><span class="title">dataStream</span>.<span class="title">addSink</span>(<span class="params"> esSinkBuilder.build(</span>) )</span></span><br><span class="line"><span class="class"></span></span><br></pre></td></tr></table></figure>

<h3 id="JDBC-1-10没有"><a href="#JDBC-1-10没有" class="headerlink" title="JDBC(1.10没有)"></a>JDBC(1.10没有)</h3><p><strong>1.11后有，这种不够灵活，不能根据情况进行插入或者更新。</strong></p>
<p><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/connectors/jdbc.html">Apache Flink 1.12 Documentation: JDBC Connector</a></p>
<p>This connector provides a sink that writes data to a JDBC database.</p>
<p>To use it, add the following dependency to your project (along with your JDBC-driver):</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Note that the streaming connectors are currently <strong>NOT</strong> part of the binary distribution. See how to link with them for cluster execution <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/dev/project-configuration.html">here</a>.</p>
<p>Created JDBC sink provides at-least-once guarantee. Effectively exactly-once can be achieved using upsert statements or idempotent updates.</p>
<p>Example usage:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment();</span><br><span class="line">env</span><br><span class="line">        .fromElements(...)</span><br><span class="line">        .addSink(<span class="type">JdbcSink</span>.sink(</span><br><span class="line">                <span class="string">&quot;insert into books (id, title, author, price, qty) values (?,?,?,?,?)&quot;</span>,</span><br><span class="line">                (ps, t) -&gt; &#123;</span><br><span class="line">                    ps.setInt(<span class="number">1</span>, t.id);</span><br><span class="line">                    ps.setString(<span class="number">2</span>, t.title);</span><br><span class="line">                    ps.setString(<span class="number">3</span>, t.author);</span><br><span class="line">                    ps.setDouble(<span class="number">4</span>, t.price);</span><br><span class="line">                    ps.setInt(<span class="number">5</span>, t.qty);</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="keyword">new</span> <span class="type">JdbcConnectionOptions</span>.<span class="type">JdbcConnectionOptionsBuilder</span>()</span><br><span class="line">                        .withUrl(getDbMetadata().getUrl())</span><br><span class="line">                        .withDriverName(getDbMetadata().getDriverClass())</span><br><span class="line">                        .build()));</span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<p>Please refer to the <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/api/java/org/apache/flink/connector/jdbc/JdbcSink.html">API documentation</a> for more details.</p>
<h4 id="自定义-1"><a href="#自定义-1" class="headerlink" title="自定义"></a>自定义</h4><p>1.10以及以前没有官方的，需要自定义。需要使用富函数的<code>SinkFunction</code>，使用富函数的生命周期来创建和关闭JDBC的连接</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyJdbcSink</span>(<span class="params"></span>) <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>[<span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> conn: <span class="type">Connection</span> = _</span><br><span class="line">  <span class="keyword">var</span> insertStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line">  <span class="keyword">var</span> updateStmt: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">  <span class="comment">// open 主要是创建连接</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">super</span>.open(parameters)</span><br><span class="line"></span><br><span class="line">    conn = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://localhost:3306/test&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">    insertStmt = conn.prepareStatement(<span class="string">&quot;INSERT INTO temperatures (sensor, temp) VALUES (?, ?)&quot;</span>)</span><br><span class="line">    updateStmt = conn.prepareStatement(<span class="string">&quot;UPDATE temperatures SET temp = ? WHERE sensor = ?&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用连接，执行sql</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: <span class="type">SensorReading</span>, context: <span class="type">SinkFunction</span>.<span class="type">Context</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    </span><br><span class="line">updateStmt.setDouble(<span class="number">1</span>, value.temperature)</span><br><span class="line">    updateStmt.setString(<span class="number">2</span>, value.id)</span><br><span class="line">    updateStmt.execute()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (updateStmt.getUpdateCount == <span class="number">0</span>) &#123;</span><br><span class="line">      insertStmt.setString(<span class="number">1</span>, value.id)</span><br><span class="line">      insertStmt.setDouble(<span class="number">2</span>, value.temperature)</span><br><span class="line">      insertStmt.execute()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    insertStmt.close()</span><br><span class="line">    updateStmt.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="转换算子"><a href="#转换算子" class="headerlink" title="转换算子"></a><a href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90">转换算子</a></h2><p>在这一小节我们将大概看一下DataStream API的基本转换算子。与时间有关的操作符（例如窗口操作符和其他特殊的转换算子）将会在后面的章节叙述。一个流的转换操作将会应用在一个或者多个流上面，这些转换操作将流转换成一个或者多个输出流。编写一个DataStream API简单来说就是将这些转换算子组合在一起来构建一个数据流图，这个数据流图就实现了我们的业务逻辑。</p>
<p><font color="red"><strong>大部分的流转换操作都基于用户自定义函数UDF</strong></font>。UDF函数打包了一些业务逻辑并定义了输入流的元素如何转换成输出流的元素。像<code>MapFunction</code>这样的函数，将会被定义为类，这个类实现了Flink针对特定的转换操作暴露出来的接口。虽然匿名函数很方便，但是逻辑复杂时过长的匿名函数会显得逻辑混乱。</p>
<p>DataStream API针对大多数数据转换操作提供了转换算子。如果你很熟悉批处理API、函数式编程语言或者SQL，那么你将会发现这些API很容易学习。我们会将DataStream API的转换算子分成四类：</p>
<ul>
<li>基本转换算子：将会作用在数据流中的每一条单独的数据上。</li>
<li>KeyedStream转换算子：在数据有key的情况下，对数据应用转换算子。</li>
<li>多流转换算子：合并多条流为一条流或者将一条流分割为多条流。</li>
<li>分布式转换算子：将重新组织流里面的事件。</li>
</ul>
<h3 id="基本转换算子"><a href="#基本转换算子" class="headerlink" title="基本转换算子"></a><a href="#%E5%9F%BA%E6%9C%AC%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90">基本转换算子</a></h3><p><strong>基本转换算子会针对流中的每一个单独的事件做处理，也就是说每一个输入数据会产生一个输出数据。</strong>单值转换，数据的分割，数据的过滤，都是基本转换操作的典型例子。我们将解释这些算子的语义并提供示例代码。</p>
<h4 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a><em>MAP</em></h4><p><code>map</code>算子通过调用<code>DataStream.map()</code>来指定。<code>map</code>算子的使用将会产生一条新的数据流。它会将每一个输入的事件传送到一个用户自定义的mapper，这个mapper只返回一个输出事件，这个输出事件和输入事件的类型可能不一样。下图展示了一个map算子，这个map将每一个正方形转化成了圆形。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0501.png" alt="img"></p>
<p><code>MapFunction</code>的类型与输入事件和输出事件的类型相关，可以通过实现<code>MapFunction</code>接口来定义。接口包含<code>map()</code>函数，这个函数将一个输入事件恰好转换为一个输出事件。</p>
<p>下面的代码实现了将SensorReading中的id字段抽取出来的功能。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> readings: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = readings.map(<span class="keyword">new</span> <span class="type">IdExtractor</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IdExtractor</span> <span class="keyword">extends</span> <span class="title">MapFunction</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(r: <span class="type">SensorReading</span>) : <span class="type">String</span> = r.id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当然我们更推荐匿名函数的写法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorIds: <span class="type">DataStream</span>[<span class="type">String</span>] = filteredReadings.map(r =&gt; r.id)</span><br></pre></td></tr></table></figure>

<h4 id="FILTER"><a href="#FILTER" class="headerlink" title="FILTER"></a><em>FILTER</em></h4><p><code>filter</code>转换算子通过在每个输入事件上对一个布尔条件进行求值来过滤掉一些元素，然后将剩下的元素继续发送。一个<code>true</code>的求值结果将会把输入事件保留下来并发送到输出，而如果求值结果为<code>false</code>，则输入事件会被抛弃掉。我们通过调用<code>DataStream.filter()</code>来指定流的<code>filter</code>算子，<code>filter</code>操作将产生一条新的流，其类型和输入流中的事件类型是一样的。下图展示了只产生白色方框的<code>filter</code>操作。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0502.png" alt="img"></p>
<p>布尔条件可以使用函数、FilterFunction接口或者匿名函数来实现。FilterFunction中的泛型是输入事件的类型。定义的<code>filter()</code>方法会作用在每一个输入元素上面，并返回一个布尔值。</p>
<p>下面的例子展示了如何使用filter来从传感器数据中过滤掉温度值小于25华氏温度的读数。</p>
<p><code>val filteredReadings = readings.filter(r =&gt; r.temperature &gt;= 25)</code></p>
<h4 id="FLATMAP"><a href="#FLATMAP" class="headerlink" title="FLATMAP"></a><em>FLATMAP</em></h4><p><code>flatMap</code>算子和<code>map</code>算子很类似，不同之处在于针对每一个输入事件<code>flatMap</code>可以生成0个、1个或者多个输出元素。事实上，<code>flatMap</code>转换算子是<code>filter</code>和<code>map</code>的泛化。所以<code>flatMap</code>可以实现<code>map</code>和<code>filter</code>算子的功能。下图展示了<code>flatMap</code>如何根据输入事件的颜色来做不同的处理。如果输入事件是白色方框，则直接输出。输入元素是黑框，则复制输入。灰色方框会被过滤掉。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0503.png" alt="img"></p>
<p>flatMap算子将会应用在每一个输入事件上面。对应的<code>FlatMapFunction</code>定义了<code>flatMap()</code>方法，这个方法返回0个、1个或者多个事件到一个<code>Collector</code>集合中，作为输出结果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; T: the type of input elements</span><br><span class="line">&#x2F;&#x2F; O: the type of output elements</span><br><span class="line">FlatMapFunction[T, O]</span><br><span class="line">    &gt; flatMap(T, Collector[O]): Unit</span><br></pre></td></tr></table></figure>

<p>下面的例子展示了在数据分析教程中经常用到的例子，我们用<code>flatMap</code>来实现。使用<code>_</code>来切割传感器ID，比如<code>sensor_1</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IdSplitter</span> <span class="keyword">extends</span> <span class="title">FlatMapFunction</span>[<span class="type">String</span>, <span class="type">String</span>] </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(id: <span class="type">String</span>, out: <span class="type">Collector</span>[<span class="type">String</span>]) : <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> arr = id.split(<span class="string">&quot;_&quot;</span>)</span><br><span class="line">        arr.foreach(out.collect)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>匿名函数写法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> splitIds = sensorIds</span><br><span class="line">  .flatMap(r =&gt; r.split(<span class="string">&quot;_&quot;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="键控流转换算子"><a href="#键控流转换算子" class="headerlink" title="键控流转换算子"></a><a href="#%E9%94%AE%E6%8E%A7%E6%B5%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90">键控流转换算子</a></h3><p>很多流处理程序的一个基本要求就是要能<font color="red">对数据进行分组，分组后的数据共享某一个相同的属性</font>。DataStream API提供了一个叫做<code>KeyedStream</code>的抽象，此抽象会从<strong>逻辑上对DataStream进行分区</strong>，分区后的数据拥有同样的<code>Key</code>值，分区后的流互不相关。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/Snipaste_2020-12-19_10-47-17.png"></p>
<p>而Spark的分组函数不是这样，因为它是批处理。所以他不是一个事件执行一个分组，而是一批数据执行一次分组。所以它的分组之后是K,[V]的事件，即它的分组函数是物理分组。</p>
<hr>
<p>针对KeyedStream的状态转换操作可以读取数据或者写入数据到当前事件Key所对应的状态中。<strong>这表明拥有同样Key的所有事件都可以访问同样的状态</strong>，也就是说所以这些事件可以一起处理。</p>
<blockquote>
<p>也就是说分组后的每个key所在的分区都会维护一个状态，为了之后的滚动计算分区内的值，每当分区中的一个事件到来时，都会与之前保存好的状态相计算，得到最新的状态。而每个key的状态都是隔离的。</p>
</blockquote>
<blockquote>
<p>要小心使用状态转换操作和基于Key的聚合操作。如果Key的值越来越多，例如：Key是订单ID，我们必须及时清空Key所对应的状态，以免引起内存方面的问题。稍后我们会详细讲解。</p>
</blockquote>
<p>KeyedStream可以使用map，flatMap和filter算子来处理。接下来我们会使用keyBy算子来将DataStream转换成KeyedStream，并讲解基于key的转换操作：<strong>滚动聚合和reduce算子。</strong></p>
<h4 id="KEYBY"><a href="#KEYBY" class="headerlink" title="KEYBY"></a><em>KEYBY</em></h4><p>keyBy通过指定key来将DataStream转换成KeyedStream。基于不同的key，流中的事件将被分配到不同的分区中去。所有具有相同key的事件将会在接下来的操作符的同一个子任务槽中进行处理。拥有不同key的事件可以在同一个任务中处理。但是算子只能访问当前事件的key所对应的状态。</p>
<p>如下图所示，把输入事件的颜色作为key，黑色的事件输出到了一个分区，其他颜色输出到了另一个分区。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0504.png"></p>
<p><code>keyBy()</code>方法接收一个参数，这个参数指定了key或者keys，有很多不同的方法来指定key。我们将在后面讲解。下面的代码声明了<code>id</code>这个字段为SensorReading流的key。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> keyed: <span class="type">KeyedStream</span>[<span class="type">SensorReading</span>, <span class="type">String</span>] = readings.keyBy(r =&gt; r.id)</span><br></pre></td></tr></table></figure>

<p>匿名函数<code>r =&gt; r.id</code>抽取了传感器读数SensorReading的id值。</p>
<h4 id="滚动聚合🔺"><a href="#滚动聚合🔺" class="headerlink" title="滚动聚合🔺"></a><em>滚动聚合</em>🔺</h4><p><font color="red"><strong>滚动聚合算子由<code>KeyedStream</code>调用，并生成一个聚合以后的DataStream</strong></font>，例如：sum，minimum，maximum。<strong>一个滚动聚合算子会为每一个观察到的key保存一个聚合的值</strong>。<strong>针对每一个输入事件，算子将会更新保存的聚合结果</strong>，并发送一个带有更新后的值的事件到下游算子。<strong>滚动聚合不需要用户自定义函数，但需要接受一个参数，这个参数指定了在哪一个字段上面做聚合操作</strong>。DataStream API提供了以下滚动聚合方法。</p>
<ul>
<li>sum()：在输入流上对指定的字段做滚动相加操作。</li>
<li>min()：在输入流上对指定的字段求最小值。</li>
<li>max()：在输入流上对指定的字段求最大值。</li>
<li>minBy()：在输入流上针对指定字段求最小值，并返回包含当前观察到的最小值的事件。</li>
<li>maxBy()：在输入流上针对指定字段求最大值，并返回包含当前观察到的最大值的事件。</li>
</ul>
<p>滚动聚合算子无法组合起来使用，每次计算只能使用一个单独的滚动聚合算子。</p>
<blockquote>
<p>因为滚动聚合算子只能对<code>KeyedStream</code>调用，且调用后会变为<code>DataStream</code></p>
</blockquote>
<p>下面的例子根据第一个字段来对类型为<code>Tuple3</code>的流做分流操作，然后针对第二个字段做滚动求和操作。</p>
<p><strong>scala version</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> inputStream = env.fromElements((<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> resultStream = inputStream.keyBy(<span class="number">0</span>).sum(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>在这个例子里面，输入流根据第一个字段来分流，然后在第二个字段上做计算。对于key 1，输出结果是(1,2,2),(1,7,2)。对于key 2，输出结果是(2,3,1),(2,5,1)。第一个字段是key，第二个字段是求和的数值，第三个字段未定义。</p>
<blockquote>
<p>滚动聚合操作会对每一个key都保存一个状态。因为状态从来不会被清空，所以我们在使用滚动聚合算子时只能使用在<font color="red">含有有限个key的流上面。</font></p>
</blockquote>
<h4 id="REDUCE🔺"><a href="#REDUCE🔺" class="headerlink" title="REDUCE🔺"></a><em>REDUCE</em>🔺</h4><p>reduce算子是滚动聚合的泛化实现。<strong>它将一个ReduceFunction应用到了一个KeyedStream上面去。</strong>reduce算子将会把每一个输入事件和当前已经reduce出来的值做聚合计算。<strong>reduce操作不会改变流的事件类型。输出流数据类型和输入流数据类型是一样的。</strong></p>
<blockquote>
<p>实际上reduce方法就是自定义的滚动聚合方法，与之不同的是它不会改变流类型，使用会不会将KeyedStream[T]-&gt;DataStream[T1]</p>
</blockquote>
<p>reduce函数可以通过实现接口ReduceFunction来创建一个类。ReduceFunction接口定义了<code>reduce()</code>方法，此方法接收两个输入事件，输入一个相同类型的事件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; T: the element type</span><br><span class="line">ReduceFunction[T]</span><br><span class="line">    &gt; reduce(T, T): T</span><br></pre></td></tr></table></figure>

<p>下面的例子，流根据传感器ID分流，然后计算每个传感器的当前最大温度值。</p>
<p><strong>scala version</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyReduce</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> value: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    <span class="keyword">val</span> value1: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = value.keyBy(_.id).reduce(<span class="keyword">new</span> myReduce)</span><br><span class="line">    value1.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">myReduce</span> <span class="keyword">extends</span> <span class="title">ReduceFunction</span>[<span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(t: <span class="type">SensorReading</span>, t1: <span class="type">SensorReading</span>): <span class="type">SensorReading</span> = &#123;</span><br><span class="line">     <span class="keyword">if</span> (t.temperature&gt;t1.temperature) &#123;</span><br><span class="line">       t</span><br><span class="line">     &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">       t1</span><br><span class="line">     &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>reduce作为滚动聚合的泛化实现，同样也要针对每一个key保存状态。因为状态从来不会清空，<font color="red">所以我们需要将reduce算子应用在一个有限key的流上。</font></p>
</blockquote>
<h3 id="多流转换算子"><a href="#多流转换算子" class="headerlink" title="多流转换算子"></a><a href="#%E5%A4%9A%E6%B5%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90">多流转换算子</a></h3><p>许多应用需要摄入多个流并将流合并处理，还可能需要将一条流分割成多条流然后针对每一条流应用不同的业务逻辑。接下来，我们将讨论DataStream API中提供的能够处理多条输入流或者发送多条输出流的操作算子。</p>
<h4 id="UNION"><a href="#UNION" class="headerlink" title="UNION"></a><em>UNION</em></h4><p>DataStream.union()方法将两条或者多条DataStream合并成一条具有<strong>与输入流相同类型的输出DataStream</strong>。接下来的转换算子将会处理输入流中的所有元素。下图展示了union操作符如何将黑色和白色的事件流合并成一个单一输出流。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0505.png" alt="img"></p>
<p>事件合流的方式为FIFO方式。操作符并不会产生一个特定顺序的事件流。<strong>union操作符也不会进行去重。每一个输入事件都被发送到了下一个操作符。</strong></p>
<p>下面的例子展示了如何将三条类型为SensorReading的数据流合并成一条流。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> parisStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> tokyoStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> rioStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = ...</span><br><span class="line"><span class="keyword">val</span> allCities: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = parisStream</span><br><span class="line">  .union(tokyoStream, rioStream)</span><br></pre></td></tr></table></figure>

<h4 id="CONNECT-COMAP和COFLATMAP🔺"><a href="#CONNECT-COMAP和COFLATMAP🔺" class="headerlink" title="CONNECT, COMAP和COFLATMAP🔺"></a><em>CONNECT, COMAP和COFLATMAP</em>🔺</h4><p>联合两条流的事件是非常常见的流处理需求。例如监控一片森林然后发出高危的火警警报。报警的Application接收两条流，一条是温度传感器传回来的数据，一条是烟雾传感器传回来的数据。当两条流都超过各自的阈值时，报警。</p>
<p>DataStream API提供了<code>connect</code>操作来支持以上的应用场景。<code>DataStream.connect()</code>方法接收一条<code>DataStream</code>，然后返回一个<code>ConnectedStreams</code>类型的对象，这个对象表示了两条连接的流。</p>
<p>ConnectedStreams提供了<code>map()</code>和<code>flatMap()</code>方法，分别需要接收类型为<code>CoMapFunction</code>和<code>CoFlatMapFunction</code>的参数。</p>
<p>以上两个函数里面的泛型是第一条流的事件类型和第二条流的事件类型，以及输出流的事件类型。还定义了两个方法，每一个方法针对一条流来调用。<code>map1()</code>和<code>flatMap1()</code>会调用在第一条流的元素上面，<code>map2()</code>和<code>flatMap2()</code>会调用在第二条流的元素上面。flatmap的flatmap函数可以发送多个值，而map只能一个。</p>
<p>对两条流做连接查询通常需要这两条流基于某些条件被确定性的路由到操作符中相同的并行实例里面去。<strong>在默认情况下，connect()操作将不会对两条流的事件建立任何关系，所以两条流的事件将会随机的被发送到下游的算子实例里面去。</strong>这样的行为会产生不确定性的计算结果，显然不是我们想要的。<font color="red">为了针对ConnectedStreams进行确定性的转换操作，connect()方法可以和keyBy()或者broadcast()组合起来使用。我们首先看一下keyBy()的示例。</font></p>
<ul>
<li>使用keyBy指定key来对两条流建立关系</li>
</ul>
<p><strong>keyby</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> one = ...</span><br><span class="line"><span class="keyword">val</span> two = ...</span><br><span class="line"><span class="comment">// 写法1</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect1 = one.connect(two).keyBy(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment">// 写法2</span></span><br><span class="line"><span class="keyword">val</span> keyedConnect2 = one.keyBy(<span class="number">0</span>).connect(two.keyBy(<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> one: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = env.fromElements((<span class="number">1</span>, <span class="string">&quot;a&quot;</span>), (<span class="number">2</span>,<span class="string">&quot;b&quot;</span>))</span><br><span class="line">    <span class="keyword">val</span> two: <span class="type">DataStream</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = env.fromElements((<span class="number">1</span>, <span class="string">&quot;m&quot;</span>), (<span class="number">2</span>,<span class="string">&quot;n&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> keyedConnect2: <span class="type">ConnectedStreams</span>[(<span class="type">Int</span>, <span class="type">String</span>), (<span class="type">Int</span>, <span class="type">String</span>)] = one.keyBy(<span class="number">0</span>).connect(two.keyBy(<span class="number">0</span>))</span><br><span class="line">    keyedConnect2.map(<span class="keyword">new</span> <span class="type">MyCoMap</span>).print()</span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyCoMap</span> <span class="keyword">extends</span> <span class="title">CoMapFunction</span>[(<span class="type">Int</span>, <span class="type">String</span>),(<span class="type">Int</span>, <span class="type">String</span>),<span class="type">String</span>]</span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map1</span></span>(in1: (<span class="type">Int</span>, <span class="type">String</span>)): <span class="type">String</span> = &#123;</span><br><span class="line">      in1._1+in1._2</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map2</span></span>(in1: (<span class="type">Int</span>, <span class="type">String</span>)): <span class="type">String</span> = &#123;</span><br><span class="line">      in1._1+in1._2</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出：1a 1m 2b 2n</span></span><br></pre></td></tr></table></figure>

<h4 id="SideOutput"><a href="#SideOutput" class="headerlink" title="SideOutput"></a><em>SideOutput</em></h4><p>大部分的DataStream API的算子的输出是单一输出，也就是某种数据类型的流。除了split算子，可以将一条流分成多条流，这些流的数据类型也都相同。process function的side outputs功能可以产生多条流，并且这些流的数据类型可以不一样。一个side output可以定义为OutputTag[X]对象，<strong>X是输出流的数据类型</strong>。process function可以通过Context对象发射一个事件到一个或者多个side outputs。</p>
<blockquote>
<p><code>process function</code>与<code>KeyedProcessFunction</code>区别：</p>
<p><code>KeyedProcessFunction</code>是对于keyby后的流计算，而<code>process function</code>是对keyby前的流计算，都是一个元素触发一次计算</p>
</blockquote>
<p><strong>将数据发送到不同的侧输出流</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SideOutputStream</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> inputStream: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    inputStream.process(<span class="keyword">new</span> <span class="type">MySideOutputStream</span>).getSideOutput(<span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">SensorReading</span>](<span class="string">&quot;tmp&quot;</span>))</span><br><span class="line">      .print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//  ProcessFunction`处理的是没有 kelBy的流</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MySideOutputStream</span> <span class="keyword">extends</span> <span class="title">ProcessFunction</span>[<span class="type">SensorReading</span>, <span class="type">SensorReading</span>]</span>&#123;</span><br><span class="line">    <span class="keyword">lazy</span> <span class="keyword">private</span> <span class="keyword">val</span> tag: <span class="type">OutputTag</span>[<span class="type">SensorReading</span>] = <span class="keyword">new</span> <span class="type">OutputTag</span>[<span class="type">SensorReading</span>](<span class="string">&quot;tmp&quot;</span>)</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(i: <span class="type">SensorReading</span>, context: <span class="type">ProcessFunction</span>[<span class="type">SensorReading</span>, <span class="type">SensorReading</span>]#<span class="type">Context</span>, collector: <span class="type">Collector</span>[<span class="type">SensorReading</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="comment">// 满足指定条件则输入到侧输出流，所有元素都需要发送到正常流</span></span><br><span class="line">      <span class="keyword">if</span> (i.temperature&lt;<span class="number">10.0</span>) &#123;</span><br><span class="line">        context.output(tag, i)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      collector.collect(i)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20210102142714440.png" alt="image-20210102142714440"></p>
<h3 id="分布式转换算子"><a href="#分布式转换算子" class="headerlink" title="分布式转换算子"></a><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90">分布式转换算子</a></h3><p>当我们使用DataStream API来编写程序时，系统将自动的选择数据分区策略，然后根据操作符的语义和设置的并行度将数据路由到正确的地方去。有些时候，我们需要在应用程序的层面控制分区策略，或者自定义分区策略。例如，如果我们知道会发生数据倾斜，那么我们想要针对数据流做负载均衡，将数据流平均发送到接下来的操作符中去。又或者，应用程序的业务逻辑可能需要一个算子所有的并行任务都需要接收同样的数据。再或者，我们需要自定义分区策略的时候。在这一小节，我们将展示DataStream的一些方法，可以使我们来控制或者自定义数据分区策略。</p>
<blockquote>
<p>keyBy()方法不同于分布式转换算子。所有的分布式转换算子将产生DataStream数据类型。而keyBy()产生的类型是KeyedStream，它拥有自己的keyed state。</p>
<p>分布式转换算子实际上就是shuffle将原有分区的数据发送到下一任务的不同分区。如果下一任务有多个并行，则有用，如果就一个它怎么发还是给一个并行度1的任务执行</p>
</blockquote>
<p>数据交换策略如下：</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0203.png"></p>
<ul>
<li>前向策略将数据从一个任务发送到接收任务。如果两个任务都位于同一台物理计算机上（这通常由任务调度器确保），这种交换策略可以避免网络通信。</li>
<li>广播策略将所有数据发送到算子的所有的并行任务上面去。因为这种策略会复制数据和涉及网络通信，所以代价相当昂贵。</li>
<li>基于键控的策略通过Key值(键)对数据进行分区保证具有相同Key的数据将由同一任务处理。在图2-2中，输出“Extract hashtags”算子使用键来分区（hashtag），以便count算子的任务可以正确计算每个#标签的出现次数。</li>
<li>随机策略统一将数据分配到算子的任务中去，以便均匀地将负载分配到不同的计算任务。</li>
</ul>
<h4 id="Random"><a href="#Random" class="headerlink" title="Random"></a><em>Random</em></h4><p>随机数据交换由<code>DataStream.shuffle()</code>方法实现。shuffle方法将数据随机的分配到下游算子的并行任务中去。</p>
<h4 id="Round-Robin"><a href="#Round-Robin" class="headerlink" title="Round-Robin"></a><em>Round-Robin</em></h4><p><code>rebalance()</code>方法使用Round-Robin负载均衡算法将输入流平均分配到随后的并行运行的任务中去。图5-7为round-robin分布式转换算子的示意图。</p>
<h4 id="Rescale"><a href="#Rescale" class="headerlink" title="Rescale"></a><em>Rescale</em></h4><p><code>rescale()</code>方法使用的也是round-robin算法，但只会将数据发送到接下来的并行运行的任务中的一部分任务中。本质上，当发送者任务数量和接收者任务数量不一样时，rescale分区策略提供了一种轻量级的负载均衡策略。<font color="red">如果接收者任务的数量是发送者任务的数量的倍数时，rescale操作将会效率更高。</font></p>
<p><code>rebalance()</code>和<code>rescale()</code>的根本区别在于任务之间连接的机制不同。 <code>rebalance()</code>将会针对所有发送者任务和所有接收者任务之间建立通信通道，而<code>rescale()</code>仅仅针对每一个任务和下游算子的一部分子并行任务之间建立通信通道。rescale的示意图为图5-7。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/spaf_0507.png" alt="5-7"></p>
<h4 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a><em>Broadcast</em></h4><p><code>broadcast()</code>方法将输入流的所有数据复制并发送到下游算子的所有并行任务中去。</p>
<h4 id="Global"><a href="#Global" class="headerlink" title="Global"></a><em>Global</em></h4><p><code>global()</code>方法将所有的输入流数据都发送到下游算子的第一个并行任务中去。这个操作需要很谨慎，因为将所有数据发送到同一个task，将会对应用程序造成很大的压力。</p>
<h4 id="Custom"><a href="#Custom" class="headerlink" title="Custom"></a><em>Custom</em></h4><p>当Flink提供的分区策略都不适用时，我们可以使用<code>partitionCustom()</code>方法来自定义分区策略。这个方法接收一个<code>Partitioner</code>对象，这个对象需要实现分区逻辑以及定义针对流的哪一个字段或者key来进行分区。</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/Snipaste_2020-12-19_14-38-09.png" alt="Snipaste_2020-12-19_14-38-09"></p>
<h2 id="设置并行度"><a href="#设置并行度" class="headerlink" title="设置并行度"></a><a href="#%E8%AE%BE%E7%BD%AE%E5%B9%B6%E8%A1%8C%E5%BA%A6">设置并行度</a></h2><p>Flink应用程序在一个像集群这样的分布式环境中并行执行。当一个数据流程序提交到作业管理器执行时，系统将会创建一个数据流图，然后准备执行需要的操作符。每一个操作符将会并行化到一个或者多个任务中去。每个算子的并行任务都会处理这个算子的输入流中的一份子集。一个算子并行任务的个数叫做算子的并行度。它决定了算子执行的并行化程度，以及这个算子能处理多少数据量。</p>
<p>一般设置并行度，我们不要在代码里设置全局并行度，这样硬编码不好，应当使用集群默认并行度，这样当集群扩充节点时，可以改变当前运行job的并行度，这样代码就不用重改代码实现并行度的增加。如果写死了，集群再怎么设置，并行度也不会变化。那么我们就应该对特定的算子进行并行度的计算。</p>
<p>在下面的例子里面，数据源的操作符将会按照环境默认的并行度来并行执行，map操作符的并行度将会是默认并行度的2倍，sink操作符的并行度为2。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment;</span><br><span class="line">int defaultP = env.getParallelism;</span><br><span class="line">env</span><br><span class="line">  .addSource(<span class="keyword">new</span> <span class="type">CustomSource</span>)</span><br><span class="line">  .map(<span class="keyword">new</span> <span class="type">MyMapper</span>)</span><br><span class="line">  .setParallelism(defaultP * <span class="number">2</span>)</span><br><span class="line">  .print()</span><br><span class="line">  .setParallelism(<span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<p>当我们通过客户端将应用程序的并行度设置为16并提交执行时，source操作符的并行度为16，mapper并行度为32，sink并行度为2。如果我们在本地环境运行应用程序的话，例如在IDE中运行，机器是8核，那么source任务将会并行执行在8个任务上面，mapper运行在16个任务上面，sink运行在2个任务上面。</p>
<h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a><a href="#%E7%B1%BB%E5%9E%8B">类型</a></h2><p>Flink程序所处理的流中的事件一般是对象类型。操作符接收对象输出对象。所以Flink的内部机制需要能够处理事件的类型。在网络中传输数据，或者将数据写入到状态后端、检查点和保存点中，都需要我们对数据进行序列化和反序列化。为了高效的进行此类操作，Flink需要流中事件类型的详细信息。Flink使用了<code>Type Information</code>的概念来表达数据类型，这样就能针对不同的数据类型产生特定的序列化器，反序列化器和比较操作符。</p>
<p>Flink也能够通过分析输入数据和输出数据来自动获取数据的类型信息以及序列化器和反序列化器。尽管如此，在一些特定的情况下，例如匿名函数或者使用泛型的情况下，我们需要明确的提供数据的类型信息，来提高我们程序的性能。</p>
<h3 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a><a href="#%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B">支持的数据类型</a></h3><p>Flink支持Java和Scala提供的所有普通数据类型。最常用的数据类型可以做以下分类：</p>
<ul>
<li>Primitives（原始数据类型）</li>
<li>Java和Scala的Tuples（元组）</li>
<li>Scala的样例类</li>
<li>POJO类型</li>
<li>一些特殊的类型</li>
</ul>
<p>接下来让我们一探究竟。</p>
<p><em>Primitives</em></p>
<p>Java和Scala提供的所有原始数据类型都支持，例如<code>Int</code>(Java的<code>Integer</code>)，String，Double等等。下面举一个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream[Long] numbers = env.fromElements(<span class="number">1L</span>, <span class="number">2L</span>, <span class="number">3L</span>, <span class="number">4L</span>);</span><br><span class="line">numbers.map(n -&gt; n + <span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p><em>Tuples</em></p>
<p>元组是一种组合数据类型，由固定数量的元素组成。</p>
<p>Flink为Java的Tuple提供了高效的实现。Flink实现的Java Tuple最多可以有25个元素，根据元素数量的不同，Tuple都被实现成了不同的类：Tuple1，Tuple2，一直到Tuple25。Tuple类是强类型。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; persons = env</span><br><span class="line">  .fromElements(</span><br><span class="line">    Tuple2.of(<span class="string">&quot;Adam&quot;</span>, <span class="number">17</span>),</span><br><span class="line">    Tuple2.of(<span class="string">&quot;Sarah&quot;</span>, <span class="number">23</span>)</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">persons.filter(p -&gt; p.f1 &gt; <span class="number">18</span>);</span><br></pre></td></tr></table></figure>

<p>Tuple的元素可以通过它们的public属性访问——f0，f1，f2等等。或者使用<code>getField(int pos)</code>方法来访问，元素下标从0开始：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2</span><br><span class="line"></span><br><span class="line">Tuple2&lt;String, Integer&gt; personTuple = Tuple2.of(<span class="string">&quot;Alex&quot;</span>, <span class="number">42</span>);</span><br><span class="line">Integer age = personTuple.getField(<span class="number">1</span>); <span class="comment">// age = 42</span></span><br></pre></td></tr></table></figure>

<p>不同于Scala的Tuple，Java的Tuple是可变数据结构，所以Tuple中的元素可以重新进行赋值。重复利用Java的Tuple可以减轻垃圾收集的压力。举个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">personTuple.f1 = <span class="number">42</span>; <span class="comment">// set the 2nd field to 42</span></span><br><span class="line">personTuple.setField(<span class="number">43</span>, <span class="number">1</span>); <span class="comment">// set the 2nd field to 43</span></span><br></pre></td></tr></table></figure>

<p><em>POJO</em></p>
<p>POJO类的定义：</p>
<ul>
<li>公有类</li>
<li>无参数的公有构造器</li>
<li>所有的字段都是公有的，可以通过getters和setters访问。</li>
<li>所有字段的数据类型都必须是Flink支持的数据类型。</li>
</ul>
<p>举个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> String name;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.name = name;</span><br><span class="line">    <span class="keyword">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStream&lt;Person&gt; persons = env.fromElements(</span><br><span class="line">  <span class="keyword">new</span> Person(<span class="string">&quot;Alex&quot;</span>, <span class="number">42</span>),</span><br><span class="line">  <span class="keyword">new</span> Person(<span class="string">&quot;Wendy&quot;</span>, <span class="number">23</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><em>其他数据类型</em></p>
<ul>
<li>Array, ArrayList, HashMap, Enum</li>
<li>Hadoop Writable types</li>
</ul>
<h2 id="定义Key以及引用字段🔺"><a href="#定义Key以及引用字段🔺" class="headerlink" title="定义Key以及引用字段🔺"></a><a href="#%E5%AE%9A%E4%B9%89key%E4%BB%A5%E5%8F%8A%E5%BC%95%E7%94%A8%E5%AD%97%E6%AE%B5">定义Key以及引用字段</a>🔺</h2><p>在Flink中，我们必须明确指定输入流中的元素中的哪一个字段是key。</p>
<h3 id="使用字段位置进行keyBy"><a href="#使用字段位置进行keyBy" class="headerlink" title="使用字段位置进行keyBy"></a><a href="#%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E4%BD%8D%E7%BD%AE%E8%BF%9B%E8%A1%8Ckeyby">使用字段位置进行keyBy</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple3&lt;Int, String, Long&gt;&gt; input = ...</span><br><span class="line">KeyedStream&lt;Tuple3&lt;Int, String, Long&gt;, String&gt; keyed = input.keyBy(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>如果我们想要用元组的第2个字段和第3个字段做keyBy，可以看下面的例子。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input.keyBy(<span class="number">1</span>, <span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<h3 id="使用字段表达式来进行keyBy"><a href="#使用字段表达式来进行keyBy" class="headerlink" title="使用字段表达式来进行keyBy"></a><a href="#%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%9D%A5%E8%BF%9B%E8%A1%8Ckeyby">使用字段表达式来进行keyBy</a></h3><p>对于样例类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;SensorReading&gt; sensorStream = ...</span><br><span class="line">sensorStream.keyBy(<span class="string">&quot;id&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>对于元组：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple3&lt;Integer, String, Long&gt;&gt; javaInput = ...</span><br><span class="line">javaInput.keyBy(<span class="string">&quot;f2&quot;</span>) <span class="comment">// key Java tuple by 3rd field</span></span><br></pre></td></tr></table></figure>

<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/Snipaste_2020-12-19_14-46-16.png"></p>
<h3 id="Key选择器"><a href="#Key选择器" class="headerlink" title="Key选择器"></a><a href="#key%E9%80%89%E6%8B%A9%E5%99%A8">Key选择器</a></h3><p>方法类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KeySelector[IN, KEY]</span><br><span class="line">  &gt; getKey(IN): KEY</span><br></pre></td></tr></table></figure>

<p><strong>scala version</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sensorData = ...</span><br><span class="line"><span class="keyword">val</span> byId = sensorData.keyBy(r =&gt; r.id)</span><br></pre></td></tr></table></figure>

<p><strong>java version</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;SensorReading&gt; sensorData = ...</span><br><span class="line">KeyedStream&lt;SensorReading, String&gt; byId = sensorData.keyBy(r -&gt; r.id);</span><br></pre></td></tr></table></figure>

<h2 id="实现UDF函数，更细粒度的控制流"><a href="#实现UDF函数，更细粒度的控制流" class="headerlink" title="实现UDF函数，更细粒度的控制流"></a><a href="#%E5%AE%9E%E7%8E%B0udf%E5%87%BD%E6%95%B0%E6%9B%B4%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E6%8E%A7%E5%88%B6%E6%B5%81">实现UDF函数，更细粒度的控制流</a></h2><p>其上上面的例子已经有使用UDF自定义函数处理逻辑了。</p>
<h3 id="函数类"><a href="#函数类" class="headerlink" title="函数类"></a><a href="#%E5%87%BD%E6%95%B0%E7%B1%BB">函数类</a></h3><p>Flink暴露了所有udf函数的接口(实现方式为接口或者抽象类)。例如MapFunction, FilterFunction, ProcessFunction等等。</p>
<p>例子实现了FilterFunction接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FilterFilter</span> <span class="keyword">extends</span> <span class="title">FilterFunction</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Boolean <span class="title">filter</span><span class="params">(String value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value.contains(<span class="string">&quot;flink&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(<span class="keyword">new</span> FlinkFilter);</span><br></pre></td></tr></table></figure>

<p>还可以将函数实现成匿名类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(</span><br><span class="line">  <span class="keyword">new</span> RichFilterFunction&lt;String&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">filter</span><span class="params">(String value)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> value.contains(<span class="string">&quot;flink&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>我们filter的字符串”flink”还可以当作参数传进去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; tweets = ...</span><br><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(<span class="keyword">new</span> KeywordFilter(<span class="string">&quot;flink&quot;</span>));</span><br><span class="line"></span><br><span class="line">class KeywordFilter(keyWord: String) extends FilterFunction&lt;String&gt; &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Boolean <span class="title">filter</span><span class="params">(String value)</span> </span>= &#123;</span><br><span class="line">    <span class="keyword">return</span> value.contains(keyWord);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a><a href="#%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0">匿名函数</a></h3><p><strong>匿名函数可以实现一些简单的逻辑，但无法实现一些高级功能，例如访问状态等等。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; tweets = ...</span><br><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(r -&gt; r.contains(<span class="string">&quot;flink&quot;</span>));</span><br></pre></td></tr></table></figure>

<h3 id="富函数🔺"><a href="#富函数🔺" class="headerlink" title="富函数🔺"></a><a href="#%E5%AF%8C%E5%87%BD%E6%95%B0">富函数</a>🔺</h3><p>其实上面的数据源就是用了富函数，它可以定义更多的操作。</p>
<p>我们经常会有这样的需求<strong>：在函数处理数据之前，需要做一些初始化的工作；或者需要在处理数据时可以获得函数执行上下文的一些信息；以及在处理完数据时做一些清理工作。</strong>而DataStream API就提供了这样的机制。</p>
<p>DataStream API提供的所有转换操作函数，都拥有它们的“富”版本，并且我们在使用常规函数或者匿名函数的地方来使用富函数。例如下面就是富函数的一些例子，可以看出，<strong>只需要在常规函数的前面加上<code>Rich</code>前缀就是富函数了。</strong></p>
<ul>
<li>RichMapFunction</li>
<li>RichFlatMapFunction</li>
<li>RichFilterFunction</li>
<li>…</li>
</ul>
<p>当我们使用富函数时，我们可以实现两个额外的方法：</p>
<ul>
<li>open()方法是rich function的初始化方法，当一个算子例如map或者filter被调用之前open()会被调用。open()函数通常用来做一些只需要做一次即可的初始化工作。</li>
<li>close()方法是生命周期中的最后一个调用的方法，通常用来做一些清理工作。</li>
</ul>
<p>另外，getRuntimeContext()方法提供了函数的RuntimeContext的一些信息，例如函数执行的并行度，当前子任务的索引，当前子任务的名字。同时还它还包含了访问<strong>分区状态</strong>的方法。下面看一个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFlatMap</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>&lt;<span class="title">Integer</span>, <span class="title">Tuple2</span>&lt;<span class="title">Integer</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> subTaskIndex = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration configuration)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> subTaskIndex = getRuntimeContext.getIndexOfThisSubtask;</span><br><span class="line">    <span class="comment">// 做一些初始化工作</span></span><br><span class="line">    <span class="comment">// 例如建立一个和HDFS的连接</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(Integer in, Collector&lt;Tuple2&lt;Integer, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (in % <span class="number">2</span> == subTaskIndex) &#123;</span><br><span class="line">      out.collect((subTaskIndex, in));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 清理工作，断开和HDFS的连接。</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Window-API"><a href="#Window-API" class="headerlink" title="Window API"></a>Window API</h1><p>一般真实的流都是无界的，怎样处理无界的数据？</p>
<p>将无界流转换为有界流开始计算，因为无界流是无限制的，不会有结果。</p>
<p>可以把无限的数据流进行切分，得到有限的数据集进行处理 —— 也就是得到有界流；窗口（window）就是将无限流切割为有限流的一种方式，它会将流数据分发到有限大小的桶（bucket）中进行分析</p>
<h2 id="window-类型"><a href="#window-类型" class="headerlink" title="window 类型"></a>window 类型</h2><ol>
<li>时间窗口（Time Window）：主要写的时间窗口，计数窗口类似。<ul>
<li><a href="#%E6%97%B6%E9%97%B4%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3">滚动时间窗口</a>：<strong>Tumbling Windows</strong></li>
<li><a href="#%E6%97%B6%E9%97%B4%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3">滑动时间窗口</a>：<strong>Sliding Windows</strong></li>
<li><a href="#%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3">会话窗口</a>：<strong>Session Windows</strong></li>
</ul>
</li>
<li>计数窗口（Count Window）<ul>
<li>滚动计数窗口</li>
<li>滑动计数窗口</li>
</ul>
</li>
</ol>
<h3 id="时间窗口"><a href="#时间窗口" class="headerlink" title="时间窗口"></a>时间窗口</h3><p><font color="red">时间窗口又分为：事件时间、触发时间。默认的是触发时间窗口</font></p>
<h4 id="时间滚动窗口"><a href="#时间滚动窗口" class="headerlink" title="时间滚动窗口"></a>时间滚动窗口</h4><p><strong>Tumbling Windows</strong></p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201220215345926.png" alt="image-20201220215345926"></p>
<ol>
<li>时间对齐，窗口长度固定，没有重叠</li>
<li>滚动窗口是特殊的滑动窗口（滑动间隔=窗口长度）</li>
<li>左闭右开</li>
</ol>
<p>滚动窗口计算某一秒所在的窗口的起始时间，offset=0，ts=1…n(s)：</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201220144118892.png" alt="image-20201220144118892"></p>
<h4 id="时间滑动窗口"><a href="#时间滑动窗口" class="headerlink" title="时间滑动窗口"></a>时间滑动窗口</h4><p><strong>Sliding Windows</strong></p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201220220206360.png" alt="image-20201220220206360"></p>
<ol>
<li>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成</li>
<li>窗口长度固定，可以有重叠</li>
</ol>
<blockquote>
<p>注意：</p>
<p>因为滑动窗口在滑动间隔&lt;窗口长度时，不同的窗口会有重复的数据，为了前面的窗口的消失不影响后面窗口的数据，Flink会将数据复制分别给使用到此数据的不同窗口。</p>
<p><font color="red">所以，如果滑动间隔过小，会导致Flink复制过多的数据，造成效率严重降低。</font></p>
<p>例如：</p>
<p>窗口长度100min，窗口哦间隔1min；这样每过一分钟，就会复制此窗口的后99条数据给下一个窗口。</p>
</blockquote>
<h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p><strong>Session Windows</strong>，只有时间窗口才有会话窗口</p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201220221007431.png" alt="image-20201220221007431"></p>
<ol>
<li>由一系列事件组合一个指定时间长度的 timeout 间隙组成，也就是一段时间没有接收到新数据就会生成新的窗口</li>
<li>特点：时间无对齐</li>
</ol>
<blockquote>
<p> 指定时间长度timeout内无数据，新数据来临后会直接产生新的窗口。它可用来统计行为模式</p>
<p> 即：新来的事件和上一事件的时间间隔大于timeout的话，上一窗口直接关闭，新来的事件在新的窗口，是它的第一个事件。</p>
</blockquote>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201221150605732.png" alt="image-20201221150605732"></p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201221150626503.png" alt="image-20201221150626503"></p>
<h2 id="Window-API-1"><a href="#Window-API-1" class="headerlink" title="Window API"></a>Window API</h2><p><strong><font color="red">一般数据先分流后开窗。</font>分流后不同key可能不在一个slot中也可能不在一个taskmanager中，这样，每个key的窗口互不干涉，加大并行。</strong></p>
<h3 id="create-window"><a href="#create-window" class="headerlink" title="create window"></a>create window</h3><p><strong><em>window</em></strong></p>
<p>最底层的开窗口的方法：<code>window()</code>。用 <code>.window() </code>来定义一个窗口，然后基于这个 window 去做一些聚合或者其它处理操作。注意 window () 方法必须在 keyBy 之后才能用。</p>
<blockquote>
<p>window()与windowall()</p>
<p>windowall()是应用在DataStream上的，将所有数据放在一个窗口中</p>
<p>window()是应用在DataStream和<strong>KeydStream</strong>上的。</p>
</blockquote>
<p>而<code>window</code>方法构造时间、计数窗口是需要一个窗口分配器（<strong>window assigner</strong>）的。WindowAssigner 负责将每条输入的数据分发到正确的 window 中，Flink 提供了通用的 <strong>WindowAssigner</strong>：</p>
<ul>
<li>滚动窗口（tumbling window）</li>
<li>滑动窗口（sliding window）</li>
<li>会话窗口（session window）</li>
<li>全局窗口（global window），都在一个窗口中</li>
</ul>
<hr>
<p><strong><em>timewindow</em>,<em>countwindow</em>🔺</strong></p>
<p>window方法创建还需要<strong>window assigner</strong>，比较麻烦。Flink 提供了更加简单的<code> .timeWindow</code> 和<code>.countWindow</code> 方法，用于定义时间窗口和计数窗口。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    .keyBy(<span class="number">0</span>).timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>L))</span><br><span class="line">    .reduce((r1, _)=&gt;r1).print()</span><br></pre></td></tr></table></figure>

<p><img src="E:\Projects\sync\md\flink\Snipaste_2020-12-19_12-00-52.png" alt="image-20201220102331672"></p>
<blockquote>
<p>Flink的窗口函数和Spark的有所不同，即开窗口的类型是SensorReading而不是SensorReading[]，因为它实际上是批处理，即来一条数据给一条数据打上窗口的标签。而不是赞一个窗口的数据再处理，Flink也能这样做即使用全窗口函数<code>ProcessWindowFunction</code>。</p>
</blockquote>
<p><strong>创建不同类型的窗口</strong>：</p>
<ol>
<li><strong>滚动时间窗口（tumbling time window）</strong>：<code>.timeWindow(Time.seconds(5L))</code></li>
<li><strong>滑动时间窗口（sliding time window）</strong>：<code>.timeWindow(Time.seconds(5L), Time.seconds(1L))</code></li>
<li><strong>会话窗口（session window）</strong>：<code>.window(EventTimeSessionWindows.withGrap(Time.minutes(10)))</code></li>
<li><strong>滚动计数窗口（tumbling count window）</strong>：<code>.countWindow(Time.seconds(5L))</code></li>
<li><strong>滑动计数窗口（sliding count window）</strong>：<code>.countWindow(Time.seconds(5L), Time.seconds(1L))</code></li>
</ol>
<h3 id="window-function🔺"><a href="#window-function🔺" class="headerlink" title="window function🔺"></a>window function🔺</h3><p>window function 定义了要对窗口中收集的数据做的计算操作，可以分为两类：</p>
<ul>
<li>增量聚合函数：每条数据到来就进行计算,只保存一个简单的状态(累加器)，窗口闭合即计算完成<ul>
<li>ReduceFuntion</li>
<li>AggregateFunction<ul>
<li>merge只会在事件时间的窗口中用到</li>
</ul>
</li>
</ul>
</li>
<li>全窗口函数：先把窗口所有数据收集起来,等到计算的时候会遍历所有数据.类似于Spark的微批处理，区别是时间区域（ProcessWindowFunction，一个富函数）</li>
</ul>
<h3 id="其他API"><a href="#其他API" class="headerlink" title="其他API"></a>其他API</h3><ul>
<li>.trigger() —— 触发器：定义 window 什么时候关闭，触发计算并输出结果</li>
<li>.evictor() —— 移除器：定义移除某些数据的逻辑</li>
<li>.allowedLateness() —— 允许处理迟到的数据</li>
<li>.sideOutputLateData() —— 将迟到的数据放入侧输出流</li>
<li>.getSideOutput() —— 获取侧输出流</li>
</ul>
<h2 id="增量聚合与全量聚合"><a href="#增量聚合与全量聚合" class="headerlink" title="增量聚合与全量聚合"></a>增量聚合与全量聚合</h2><h3 id="增量聚合"><a href="#增量聚合" class="headerlink" title="增量聚合"></a>增量聚合</h3><h4 id="ReduceFunction"><a href="#ReduceFunction" class="headerlink" title="ReduceFunction"></a><em>ReduceFunction</em></h4><p>比较抽象，实现简单，实现的功能较少，不可以改变流的数据类型。</p>
<h4 id="AggregateFunction"><a href="#AggregateFunction" class="headerlink" title="AggregateFunction"></a><em>AggregateFunction</em></h4><p>比reduce实现较麻烦，但是可以改变流中的数据类型，较灵活。</p>
<blockquote>
<p>它的优点：每个窗口只用保存一个状态即可。正是因为它的优点给它带来了一些缺点：因为保存的数据少，无法计算一些场景：例如计算窗口数据的中位数，或者计算窗口数据中出现频率最高的值。</p>
<p>这时使用ReduceFunction和AggregateFunction就无法实现了。<font color="red">。这个时候就需要ProcessWindowFunction了。</font></p>
</blockquote>
<p>先来看接口定义<em>AggregateFunction</em>：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public interface <span class="type">AggregateFunction</span>&lt;<span class="type">IN</span>, <span class="type">ACC</span>, <span class="type">OUT</span>&gt;</span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Function</span>, <span class="type">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// create a new accumulator to start a new aggregate</span></span><br><span class="line">  <span class="type">ACC</span> createAccumulator();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// add an input element to the accumulator and return the accumulator</span></span><br><span class="line">  <span class="type">ACC</span> add(<span class="type">IN</span> value, <span class="type">ACC</span> accumulator);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// compute the result from the accumulator and return it.</span></span><br><span class="line">  <span class="type">OUT</span> getResult(<span class="type">ACC</span> accumulator);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// merge two accumulators and return the result.</span></span><br><span class="line">  <span class="type">ACC</span> merge(<span class="type">ACC</span> a, <span class="type">ACC</span> b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>IN是输入元素的类型，ACC是累加器的类型，OUT是输出元素的类型。</p>
<p>例如：求平均温度。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TumblingWindow</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">      .keyBy(<span class="number">0</span>).timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>L))</span><br><span class="line">      <span class="comment">// 例如计算平均温度</span></span><br><span class="line">      .aggregate(<span class="keyword">new</span> <span class="type">MyAggregate</span>).print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【流输入、累加器、流输出】</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyAggregate</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>), (<span class="type">String</span>, <span class="type">Double</span>)] </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化累加器</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (<span class="string">&quot;&quot;</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 累加逻辑</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(in: <span class="type">SensorReading</span>, acc: (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>)): (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (in.id, acc._2 + <span class="number">1</span>, acc._3 + in.temperature)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 流合并，只有事件时间（默认为触发时间窗口）窗口才会用到</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc: (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>), acc1: (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>)): (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (acc._1, acc._2 + acc1._2, acc._3 + acc1._3)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: (<span class="type">String</span>, <span class="type">Long</span>, <span class="type">Double</span>)): (<span class="type">String</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (acc._1, acc._3 / acc._2)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="全量聚合"><a href="#全量聚合" class="headerlink" title="全量聚合"></a>全量聚合</h3><h4 id="ProcessWindowFunction"><a href="#ProcessWindowFunction" class="headerlink" title="ProcessWindowFunction"></a><em>ProcessWindowFunction</em></h4><p>一些业务场景，我们需要收集窗口内所有的数据进行计算，例如计算窗口数据的中位数，或者计算窗口数据中出现频率最高的值。这样的需求，使用ReduceFunction和AggregateFunction就无法实现了。这个时候就需要ProcessWindowFunction了。</p>
<blockquote>
<p>但是，此方法虽然能获取到的信息比较多，例如：窗口信息和窗口内所有数据的集合。但是正式因为存的东西过多，将会非常占用空间。所以 有一种将ReduceFunction/AggregateFunctionProcessWindowFunction结合起来使用的方式，吸取两边的优点。<font color="red">增量聚合负责聚合，全窗口函数负责包装窗口信息</font></p>
</blockquote>
<p>先来看接口定义</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ProcessWindowFunction&lt;IN</span>, <span class="title">OUT</span>, <span class="title">KEY</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window&gt;</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">AbstractRichFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Evaluates the window</span></span><br><span class="line">  void process(<span class="type">KEY</span> key, <span class="type">Context</span> ctx, <span class="type">Iterable</span>&lt;<span class="type">IN</span>&gt; vals, <span class="type">Collector</span>&lt;<span class="type">OUT</span>&gt; out)</span><br><span class="line">    <span class="keyword">throws</span> <span class="type">Exception</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Deletes any custom per-window state when the window is purged</span></span><br><span class="line">  public void clear(<span class="type">Context</span> ctx) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The context holding window metadata</span></span><br><span class="line">  public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> <span class="title">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Returns the metadata of the window</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">W</span> window();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Returns the current processing time</span></span><br><span class="line">    public <span class="keyword">abstract</span> long currentProcessingTime();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Returns the current event-time watermark</span></span><br><span class="line">    public <span class="keyword">abstract</span> long currentWatermark();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// State accessor for per-window state</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">KeyedStateStore</span> windowState();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// State accessor for per-key global state</span></span><br><span class="line">    public <span class="keyword">abstract</span> <span class="type">KeyedStateStore</span> globalState();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Emits a record to the side output identified by the OutputTag.</span></span><br><span class="line">    public <span class="keyword">abstract</span> &lt;<span class="type">X</span>&gt; void output(<span class="type">OutputTag</span>&lt;<span class="type">X</span>&gt; outputTag, <span class="type">X</span> value);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>process()方法接受的参数为：window的key，Iterable迭代器包含窗口的所有元素，Collector用于输出结果流。Context参数和别的process方法一样。而ProcessWindowFunction的Context对象还可以访问window的元数据(窗口开始和结束时间)，当前处理时间和水位线，per-window state和per-key global state，side outputs。</p>
<ul>
<li>per-window state: 用于保存一些信息，这些信息可以被process()访问，只要process所处理的元素属于这个窗口。</li>
<li>per-key global state: 同一个key，也就是在一条KeyedStream上，不同的window可以访问per-key global state保存的值。</li>
</ul>
<p>例子：计算5s滚动窗口中平均值</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MyProcessWindowFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">DataStream</span>[<span class="type">SensorReading</span>] = env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">    source.keyBy(r=&gt;r.id).timeWindow(<span class="type">Time</span>.seconds(<span class="number">3</span>L)).process(<span class="keyword">new</span> test1).print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 输入，输出，key，窗口类型</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">test1</span> <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[<span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Long</span>, <span class="type">Long</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="comment">// 窗口最后的处理逻辑， elements是窗口中的所有事件</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>, context: <span class="type">Context</span>, elements: <span class="type">Iterable</span>[<span class="type">SensorReading</span>], out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Long</span>, <span class="type">Long</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">var</span> sum: <span class="type">Double</span> = <span class="number">0.0</span></span><br><span class="line">      <span class="keyword">val</span> size: <span class="type">Int</span> = elements.size</span><br><span class="line">      elements.foreach(x=&gt;&#123;</span><br><span class="line">        sum+=x.temperature</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">      out.collect((key, sum / size, context.window.getStart, context.window.getEnd))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>需要注意的地方</strong></p>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201221174330638.png" alt="image-20201221174330638"></p>
<h3 id="增量、全量联合使用🔺"><a href="#增量、全量联合使用🔺" class="headerlink" title="增量、全量联合使用🔺"></a>增量、全量联合使用🔺</h3><p>如果计算中位数或者出现最高频率的数据，则必须用全量聚合。但是，如果计算平均数之类的为了效率，直接使用增量聚合，然是如果还想获取到窗口的基础信息，则还需要全量聚合的封装，但是此时全量聚合不再计算，二十封装一次数据。</p>
<ol>
<li>增量聚合直接计算出结果</li>
<li>然后全量聚合根据增量聚合的结果，调整输入和输出并附加窗口信息</li>
<li>调用时通过<code>aggregate(增量, 全量)</code></li>
<li><font color="red">重要的一点，经过<code>aggregate</code>增量聚合之后，全量聚合的elements集合只有一条数据</font></li>
</ol>
<hr>
<p>例子：计算5s滚动窗口中的最低和最高的温度。输出的元素包含了(流的Key, 最低温度, 最高温度, 窗口结束时间)。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.example.flink.transform.window</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">AggregateFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.function.<span class="type">ProcessWindowFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"><span class="keyword">import</span> org.example.flink.source.&#123;<span class="type">SensorReading</span>, <span class="type">SensorSource</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">AggregateAndProcessWindow</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">out</span>(<span class="params">id: <span class="type">String</span>, max: <span class="type">Double</span>, min: <span class="type">Double</span>,var startTime: <span class="type">Long</span>,var endTime: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">  <span class="title">def</span> <span class="title">main</span>(<span class="params">args: <span class="type">Array</span>[<span class="type">String</span>]</span>)</span>: <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.addSource(<span class="keyword">new</span> <span class="type">SensorSource</span>)</span><br><span class="line">      .keyBy(r=&gt;r.id).timeWindow(<span class="type">Time</span>.seconds(<span class="number">5</span>L))</span><br><span class="line">      <span class="comment">// 例如计算平均温度</span></span><br><span class="line">      .aggregate(<span class="keyword">new</span> myAggFunction ,<span class="keyword">new</span> <span class="type">MyProcessWindowFunction</span>).print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">myAggFunction</span> <span class="keyword">extends</span> <span class="title">AggregateFunction</span>[<span class="type">SensorReading</span>, (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>), out]</span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">createAccumulator</span></span>(): (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (<span class="string">&quot;&quot;</span>, <span class="type">Double</span>.<span class="type">MinValue</span>, <span class="type">Double</span>.<span class="type">MaxValue</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(in: <span class="type">SensorReading</span>, acc: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)): (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (in.id, in.temperature.max(acc._2), in.temperature.min(acc._3))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(acc: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>), acc1: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)): (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>) = &#123;</span><br><span class="line">      (acc._1, acc._2.max(acc1._2), acc1._3.min(acc._3))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getResult</span></span>(acc: (<span class="type">String</span>, <span class="type">Double</span>, <span class="type">Double</span>)): out = &#123;</span><br><span class="line">      out(acc._1, acc._2, acc._3, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 输入，输出，key，窗口类型</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyProcessWindowFunction</span> <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>[out, out, <span class="type">String</span>, <span class="type">TimeWindow</span>] </span>&#123;</span><br><span class="line">    <span class="comment">// 因为是增量聚合的下游，所以一个窗口之会有一条数据，即聚合好的最大最小值，这里只要附加窗口信息即可，iterable只有一条数据，也不会占用过多从存储空间</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(key: <span class="type">String</span>, context: <span class="type">Context</span>, elements: <span class="type">Iterable</span>[out], out: <span class="type">Collector</span>[out]): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> head: out = elements.head</span><br><span class="line">      head.startTime = context.window.getStart</span><br><span class="line">      head.endTime = context.window.getEnd</span><br><span class="line">      out.collect(head)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这样就可以通过增量聚合减少存储的同时使用全量聚合的窗口信息。</p>
</blockquote>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20201221175646429.png" alt="image-20201221175646429"></p>
<h2 id="其他可选API"><a href="#其他可选API" class="headerlink" title="其他可选API"></a>其他可选API</h2><ul>
<li>trigger() —— 触发器：定义 window 什么时候关闭，触发计算并输出结果</li>
<li>evitor() —— 移除器：定义移除某些数据的逻辑</li>
<li>allowedLateness() —— 允许处理迟到的数据(没必要，窗口到达结束时间时立马计算不关闭，允许迟到的数据每个元素进入都会和原窗口的结果进行聚合)</li>
<li>sideOutputLateData() —— 将迟到的数据放入侧输出流（当设置的最大迟到时间之后还来了之前的数据，需要放入侧输出流），乱序、迟到数据处理</li>
<li>getSideOutput() —— 获取侧输出流</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>聚合的两种计算场景：</p>
<ol>
<li>keydStream</li>
<li>window</li>
</ol>
<p><img src="https://zxj-typora.oss-cn-shanghai.aliyuncs.com/img/image-20210101172351300.png" alt="image-20210101172351300"></p>
<h1 id="转载"><a href="#转载" class="headerlink" title="转载"></a>转载</h1><p>转载下的文章都是通过互联网上复制下来的，这样做的目的是为了能够方便查看和更好的阅读，仅此而已，谢谢各位作者~~</p>
<p><a target="_blank" rel="noopener" href="https://github.com/confucianzuoyuan/flink-tutorial">https://github.com/confucianzuoyuan/flink-tutorial</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Xiangjie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://awslzhang.top/2020/12/17/Flink-API/">https://awslzhang.top/2020/12/17/Flink-API/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://awslzhang.top" target="_blank">zxj</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Flink/">Flink</a></div><div class="post_share"><div class="social-share" data-image="https://flink.apache.org/img/flink-header-logo.svg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/12/23/Flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8CWaterMark/"><img class="prev-cover" src="https://flink.apache.org/img/flink-header-logo.svg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Flink的时间语义和watermark</div></div></a></div><div class="next-post pull-right"><a href="/2020/12/17/ready/"><img class="next-cover" src="https://images.pexels.com/photos/924824/pexels-photo-924824.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ready!</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/12/16/Flink学习笔记/" title="Flink学习笔记"><img class="cover" src="https://flink.apache.org/img/flink-header-logo.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-16</div><div class="title">Flink学习笔记</div></div></a></div><div><a href="/2021/01/02/Flink状态管理/" title="Flink状态编程和容错机制"><img class="cover" src="https://flink.apache.org/img/flink-header-logo.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-02</div><div class="title">Flink状态编程和容错机制</div></div></a></div><div><a href="/2020/12/23/Flink时间语义和WaterMark/" title="Flink的时间语义和watermark"><img class="cover" src="https://flink.apache.org/img/flink-header-logo.svg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-23</div><div class="title">Flink的时间语义和watermark</div></div></a></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Xiangjie</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">84</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">25</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XiangJie-Zhang" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:qluzxj@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DataStream-API"><span class="toc-number">1.</span> <span class="toc-text">DataStream API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">1.1.</span> <span class="toc-text">搭建执行环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Source"><span class="toc-number">1.2.</span> <span class="toc-text">Source</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka"><span class="toc-number">1.2.1.</span> <span class="toc-text">Kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">自定义</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sink"><span class="toc-number">1.3.</span> <span class="toc-text">Sink</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-1"><span class="toc-number">1.3.1.</span> <span class="toc-text">Kafka</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis"><span class="toc-number">1.3.2.</span> <span class="toc-text">Redis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ElasticSearch"><span class="toc-number">1.3.3.</span> <span class="toc-text">ElasticSearch</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JDBC-1-10%E6%B2%A1%E6%9C%89"><span class="toc-number">1.3.4.</span> <span class="toc-text">JDBC(1.10没有)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89-1"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">自定义</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">1.4.</span> <span class="toc-text">转换算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">1.4.1.</span> <span class="toc-text">基本转换算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MAP"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">MAP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FILTER"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">FILTER</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#FLATMAP"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">FLATMAP</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%AE%E6%8E%A7%E6%B5%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">1.4.2.</span> <span class="toc-text">键控流转换算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#KEYBY"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">KEYBY</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BB%9A%E5%8A%A8%E8%81%9A%E5%90%88%F0%9F%94%BA"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">滚动聚合🔺</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#REDUCE%F0%9F%94%BA"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">REDUCE🔺</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%B5%81%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">1.4.3.</span> <span class="toc-text">多流转换算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#UNION"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">UNION</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CONNECT-COMAP%E5%92%8CCOFLATMAP%F0%9F%94%BA"><span class="toc-number">1.4.3.2.</span> <span class="toc-text">CONNECT, COMAP和COFLATMAP🔺</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SideOutput"><span class="toc-number">1.4.3.3.</span> <span class="toc-text">SideOutput</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90"><span class="toc-number">1.4.4.</span> <span class="toc-text">分布式转换算子</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Random"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">Random</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Round-Robin"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">Round-Robin</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Rescale"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">Rescale</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Broadcast"><span class="toc-number">1.4.4.4.</span> <span class="toc-text">Broadcast</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Global"><span class="toc-number">1.4.4.5.</span> <span class="toc-text">Global</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Custom"><span class="toc-number">1.4.4.6.</span> <span class="toc-text">Custom</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">1.5.</span> <span class="toc-text">设置并行度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.6.</span> <span class="toc-text">类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.6.1.</span> <span class="toc-text">支持的数据类型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89Key%E4%BB%A5%E5%8F%8A%E5%BC%95%E7%94%A8%E5%AD%97%E6%AE%B5%F0%9F%94%BA"><span class="toc-number">1.7.</span> <span class="toc-text">定义Key以及引用字段🔺</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E4%BD%8D%E7%BD%AE%E8%BF%9B%E8%A1%8CkeyBy"><span class="toc-number">1.7.1.</span> <span class="toc-text">使用字段位置进行keyBy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AD%97%E6%AE%B5%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%9D%A5%E8%BF%9B%E8%A1%8CkeyBy"><span class="toc-number">1.7.2.</span> <span class="toc-text">使用字段表达式来进行keyBy</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Key%E9%80%89%E6%8B%A9%E5%99%A8"><span class="toc-number">1.7.3.</span> <span class="toc-text">Key选择器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0UDF%E5%87%BD%E6%95%B0%EF%BC%8C%E6%9B%B4%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E6%8E%A7%E5%88%B6%E6%B5%81"><span class="toc-number">1.8.</span> <span class="toc-text">实现UDF函数，更细粒度的控制流</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%B1%BB"><span class="toc-number">1.8.1.</span> <span class="toc-text">函数类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0"><span class="toc-number">1.8.2.</span> <span class="toc-text">匿名函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%8C%E5%87%BD%E6%95%B0%F0%9F%94%BA"><span class="toc-number">1.8.3.</span> <span class="toc-text">富函数🔺</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Window-API"><span class="toc-number">2.</span> <span class="toc-text">Window API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#window-%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">window 类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3"><span class="toc-number">2.1.1.</span> <span class="toc-text">时间窗口</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%BB%9A%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">时间滚动窗口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3"><span class="toc-number">2.1.1.2.</span> <span class="toc-text">时间滑动窗口</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%9A%E8%AF%9D%E7%AA%97%E5%8F%A3"><span class="toc-number">2.1.1.3.</span> <span class="toc-text">会话窗口</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Window-API-1"><span class="toc-number">2.2.</span> <span class="toc-text">Window API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#create-window"><span class="toc-number">2.2.1.</span> <span class="toc-text">create window</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#window-function%F0%9F%94%BA"><span class="toc-number">2.2.2.</span> <span class="toc-text">window function🔺</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96API"><span class="toc-number">2.2.3.</span> <span class="toc-text">其他API</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A2%9E%E9%87%8F%E8%81%9A%E5%90%88%E4%B8%8E%E5%85%A8%E9%87%8F%E8%81%9A%E5%90%88"><span class="toc-number">2.3.</span> <span class="toc-text">增量聚合与全量聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E9%87%8F%E8%81%9A%E5%90%88"><span class="toc-number">2.3.1.</span> <span class="toc-text">增量聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ReduceFunction"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">ReduceFunction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AggregateFunction"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">AggregateFunction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E9%87%8F%E8%81%9A%E5%90%88"><span class="toc-number">2.3.2.</span> <span class="toc-text">全量聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ProcessWindowFunction"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">ProcessWindowFunction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E9%87%8F%E3%80%81%E5%85%A8%E9%87%8F%E8%81%94%E5%90%88%E4%BD%BF%E7%94%A8%F0%9F%94%BA"><span class="toc-number">2.3.3.</span> <span class="toc-text">增量、全量联合使用🔺</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%8F%AF%E9%80%89API"><span class="toc-number">2.4.</span> <span class="toc-text">其他可选API</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BD%AC%E8%BD%BD"><span class="toc-number">4.</span> <span class="toc-text">转载</span></a></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/01/02/Flink%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/" title="Flink状态编程和容错机制"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink状态编程和容错机制"/></a><div class="content"><a class="title" href="/2021/01/02/Flink%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/" title="Flink状态编程和容错机制">Flink状态编程和容错机制</a><time datetime="2021-01-02T10:06:02.000Z" title="发表于 2021-01-02 18:06:02">2021-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/23/Flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8CWaterMark/" title="Flink的时间语义和watermark"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink的时间语义和watermark"/></a><div class="content"><a class="title" href="/2020/12/23/Flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%92%8CWaterMark/" title="Flink的时间语义和watermark">Flink的时间语义和watermark</a><time datetime="2020-12-23T10:59:07.000Z" title="发表于 2020-12-23 18:59:07">2020-12-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/17/Flink-API/" title="Flink Api学习"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink Api学习"/></a><div class="content"><a class="title" href="/2020/12/17/Flink-API/" title="Flink Api学习">Flink Api学习</a><time datetime="2020-12-17T12:36:28.000Z" title="发表于 2020-12-17 20:36:28">2020-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/17/ready/" title="ready!"><img src="https://images.pexels.com/photos/924824/pexels-photo-924824.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ready!"/></a><div class="content"><a class="title" href="/2020/12/17/ready/" title="ready!">ready!</a><time datetime="2020-12-16T16:02:06.000Z" title="发表于 2020-12-17 00:02:06">2020-12-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/16/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Flink学习笔记"><img src="https://flink.apache.org/img/flink-header-logo.svg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink学习笔记"/></a><div class="content"><a class="title" href="/2020/12/16/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Flink学习笔记">Flink学习笔记</a><time datetime="2020-12-16T12:29:56.000Z" title="发表于 2020-12-16 20:29:56">2020-12-16</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Xiangjie</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script></div></body></html>